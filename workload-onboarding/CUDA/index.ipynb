{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_label: \"CUDA\"\n",
        "sidebar_position: 1\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bacalhau-project/examples/blob/main/workload-onboarding/CUDA/index.ipynb)\n",
        "[![Open In Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/bacalhau-project/examples/HEAD?labpath=workload-onboarding/CUDA/index.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run CUDA programs on bacalhau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJHrbQ5wEWNm"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waqGeiuWJuDa"
      },
      "source": [
        "# What is CUDA\n",
        "\n",
        "CUDA stands for Compute Unified Device Architecture. It is an extension of C/C++ programming.\n",
        "\n",
        "CUDA is a parallel computing platform and programming model created by NVIDIA.\n",
        "it helps developers speed up their applications by harnessing the power of GPU accelerators.\n",
        "\n",
        "In addition to accelerating high performance computing (HPC) and research applications, CUDA has also been widely adopted across consumer and industrial ecosystems.\n",
        "\n",
        "\n",
        "CUDA also makes it easy for developers to take advantage of all the latest GPU architecture innovations\n",
        "\n",
        "### Advantage of GPU over CPU\n",
        "Architecturally, the CPU is composed of just a few cores with lots of cache memory that can handle a few software threads at a time. In contrast, a GPU is composed of hundreds of cores that can handle thousands of threads simultaneously.\n",
        "\n",
        "Computations like matrix multiplication could be done much faster on GPU than on CPU\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFEhH1LHRT06"
      },
      "source": [
        "## Running locally\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InHS5ShagHkE"
      },
      "source": [
        "checking if nvcc is installed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKMaPt_bHsjB",
        "outputId": "77216dd5-8892-4696-be2f-1897e21a1de8",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Downloading the programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZcLUG4XHKOg",
        "outputId": "25cb5621-dbda-44a4-ce47-7fb3f9994d63",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--2022-11-14 10:12:12--  https://raw.githubusercontent.com/tristanpenman/cuda-examples/master/00-hello-world.cu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 517 [text/plain]\n",
            "Saving to: ‘inputs/00-hello-world.cu’\n",
            "\n",
            "     0K                                                       100% 21.5M=0s\n",
            "\n",
            "2022-11-14 10:12:12 (21.5 MB/s) - ‘inputs/00-hello-world.cu’ saved [517/517]\n",
            "\n",
            "--2022-11-14 10:12:12--  https://raw.githubusercontent.com/tristanpenman/cuda-examples/master/02-cuda-hello-world-faster.cu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1231 (1.2K) [text/plain]\n",
            "Saving to: ‘inputs/02-cuda-hello-world-faster.cu’\n",
            "\n",
            "     0K .                                                     100% 49.1M=0s\n",
            "\n",
            "2022-11-14 10:12:12 (49.1 MB/s) - ‘inputs/02-cuda-hello-world-faster.cu’ saved [1231/1231]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "mkdir inputs outputs\n",
        "wget -P inputs https://raw.githubusercontent.com/tristanpenman/cuda-examples/master/00-hello-world.cu\n",
        "wget -P inputs https://raw.githubusercontent.com/tristanpenman/cuda-examples/master/02-cuda-hello-world-faster.cu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Viewing the programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6ryimnroFCY",
        "outputId": "a5c62c12-32fb-47db-91bb-dd50b54c9cf4",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#include <cmath>\n",
            "#include <iostream>\n",
            "#include <vector>\n",
            "\n",
            "int main()\n",
            "{\n",
            "    size_t n = 50000000;\n",
            "    std::vector<double> a(n);\n",
            "    std::vector<double> b(n);\n",
            "    for (int i = 0; i < n; i++) {\n",
            "        a[i] = sin(i) * sin(i);\n",
            "        b[i] = cos(i) * cos(i);\n",
            "    }\n",
            "\n",
            "    std::vector<double> c(n);\n",
            "    for (int i = 0; i < n; i++) {\n",
            "        c[i] = a[i] + b[i];\n",
            "    }\n",
            "\n",
            "    double sum = 0;\n",
            "    for (int i = 0; i < n; i++) {\n",
            "        sum += c[i];\n",
            "    }\n",
            "\n",
            "    std::cout << \"final result \" << (sum / n) << std::endl;\n",
            "\n",
            "    return 0;\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cat inputs/00-hello-world.cu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a standard c++ program which uses loops which are not parallizable so it dosen't use the most of the processing power of the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmhFN_miRm_w",
        "outputId": "159ba371-308c-4a89-d08c-e17cf33750ea",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final result 1\n",
            "final result 1\n",
            "final result 1\n",
            "final result 1\n",
            "final result 1\n",
            "final result 1\n",
            "final result 1\n",
            "final result 1\n",
            "8.6 s ± 72.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "!nvcc -o ./outputs/hello ./inputs/00-hello-world.cu; ./outputs/hello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmJB0CK1q_gi",
        "outputId": "25f3a146-741d-41db-e280-85a8e2748969",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#include <math.h>\n",
            "#include <stdio.h>\n",
            "#include <stdlib.h>\n",
            "\n",
            "__global__ void prepData(double *a, double *b, size_t n)\n",
            "{\n",
            "    const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
            "    if (idx < n) {\n",
            "        a[idx] = sin(idx) * sin(idx);\n",
            "        b[idx] = cos(idx) * cos(idx);\n",
            "    }\n",
            "}\n",
            "\n",
            "__global__ void vecAdd(double *a, double *b, double *c, size_t n)\n",
            "{\n",
            "    const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
            "    if (idx < n) {\n",
            "        c[idx] = a[idx] + b[idx];\n",
            "    }\n",
            "}\n",
            "\n",
            "int main()\n",
            "{\n",
            "    size_t n = 50000000;\n",
            "    size_t bytes = n * sizeof(double);\n",
            "    double *h_c = (double *) malloc(bytes);  // output vector\n",
            "\n",
            "    double *d_a, *d_b, *d_c;\n",
            "    cudaMalloc(&d_a, bytes);\n",
            "    cudaMalloc(&d_b, bytes);\n",
            "    cudaMalloc(&d_c, bytes);\n",
            "\n",
            "    const int blockSize = 1024;\n",
            "    const int gridSize = (int)ceil((float)n/blockSize);\n",
            "\n",
            "    prepData<<<gridSize, blockSize>>>(d_a, d_b, n);\n",
            "\n",
            "    cudaDeviceSynchronize();\n",
            "\n",
            "    vecAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n",
            "\n",
            "    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
            "\n",
            "    double sum = 0;\n",
            "    for (int i = 0; i < n; i++) {\n",
            "        sum += h_c[i];\n",
            "    }\n",
            "\n",
            "    printf(\"final result: %f\\n\", sum / n);\n",
            "\n",
            "    cudaFree(d_a);\n",
            "    cudaFree(d_b);\n",
            "    cudaFree(d_c);\n",
            "\n",
            "    free(h_c);\n",
            "\n",
            "    return 0;\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!cat inputs/02-cuda-hello-world-faster.cu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of looping we use Vector addition using CUDA and allocate the memory in advance and copy the memory to the GPU\n",
        "using cudaMemcpy so that it can utilize the HBM (High Bandwith memory of the GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kkScA_Qr4p4",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "!rm -rf outputs/hello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZX2g0NpS78s",
        "outputId": "cc65fe16-ca60-4985-eb66-3f7db3c0d51b",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final result: 1.000000\n",
            "final result: 1.000000\n",
            "final result: 1.000000\n",
            "final result: 1.000000\n",
            "final result: 1.000000\n",
            "final result: 1.000000\n",
            "final result: 1.000000\n",
            "final result: 1.000000\n",
            "1.48 s ± 46.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "!nvcc --expt-relaxed-constexpr  -o ./outputs/hello ./inputs/02-cuda-hello-world-faster.cu; ./outputs/hello"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m97QyeKnzFa"
      },
      "source": [
        "It takes around 8.67s to run \n",
        "00-hello-world.cu\n",
        "while it takes 1.39s to run\n",
        "02-cuda-hello-world-faster.cu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDBFl_L3EbFs"
      },
      "source": [
        "## Running on bacalhau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HX6GhH40jyc"
      },
      "source": [
        "Installing bacalhau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rt_B9bjEPlC",
        "outputId": "3bb982fd-4f2e-4d9f-f3bc-2be8210fe2f2",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your system is linux_amd64\n",
            "No BACALHAU detected. Installing fresh BACALHAU CLI...\n",
            "Getting the latest BACALHAU CLI...\n",
            "Installing v0.3.11 BACALHAU CLI...\n",
            "Downloading https://github.com/filecoin-project/bacalhau/releases/download/v0.3.11/bacalhau_v0.3.11_linux_amd64.tar.gz ...\n",
            "Downloading sig file https://github.com/filecoin-project/bacalhau/releases/download/v0.3.11/bacalhau_v0.3.11_linux_amd64.tar.gz.signature.sha256 ...\n",
            "Verified OK\n",
            "Extracting tarball ...\n",
            "NOT verifying Bin\n",
            "bacalhau installed into /usr/local/bin successfully.\n",
            "Client Version: v0.3.11\n",
            "Server Version: v0.3.11\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "curl -sL https://get.bacalhau.org/install.sh | bash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can easily execute the same program we ran locally using bacalhau\n",
        "\n",
        "The program is mounted by using the -u flag you can specify the link there\n",
        "-u < Link-To-The-Program >\n",
        "\n",
        "\n",
        "Docker container:  nvidia/cuda:11.2.0-cudnn8-devel-ubuntu18.04\n",
        "for executing CUDA programs you need to choose the right CUDA docker container the container should have the tag of devel in them\n",
        "\n",
        "Running the program\n",
        "-- /bin/bash -c 'nvcc --expt-relaxed-constexpr  -o ./outputs/hello ./inputs/02-cuda-hello-world-faster.cu; ./outputs/hello '\n",
        "\n",
        "we first compile the program using the nvcc compiler and save it to the outputs directory as hello\n",
        "nvcc --expt-relaxed-constexpr  -o ./outputs/hello ./inputs/02-cuda-hello-world-faster.cu\n",
        "\n",
        "then we execute the hello binary\n",
        " ./outputs/hello\n",
        "\n",
        " Note that there is ';' between the commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jQS_bUP-E-hb",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "%%bash --out job_id\n",
        " bacalhau docker run \\\n",
        "--gpu 1 \\\n",
        " -u https://raw.githubusercontent.com/tristanpenman/cuda-examples/master/02-cuda-hello-world-faster.cu \\\n",
        " --id-only \\\n",
        " --wait \\\n",
        " nvidia/cuda:11.2.0-cudnn8-devel-ubuntu18.04 \\\n",
        "-- /bin/bash -c 'nvcc --expt-relaxed-constexpr  -o ./outputs/hello ./inputs/02-cuda-hello-world-faster.cu; ./outputs/hello '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg6riPesa5BN",
        "outputId": "71899e02-8ca7-43ff-bc8d-fbcc3807b372",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: JOB_ID=22715ef6-759e-488a-9aa3-aaf2c8a79b08\n"
          ]
        }
      ],
      "source": [
        "%env JOB_ID={job_id}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0pc73fqa5BO",
        "outputId": "ad3098ee-4ef0-475c-e3ae-018f77964148",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92;100m CREATED           \u001b[0m\u001b[92;100m ID                                   \u001b[0m\u001b[92;100m JOB                                                                                                                                                                        \u001b[0m\u001b[92;100m STATE     \u001b[0m\u001b[92;100m VERIFIED \u001b[0m\u001b[92;100m PUBLISHED                                            \u001b[0m\n",
            "\u001b[97;40m 22-11-14-12:31:45 \u001b[0m\u001b[97;40m 22715ef6-759e-488a-9aa3-aaf2c8a79b08 \u001b[0m\u001b[97;40m Docker nvidia/cuda:11.2.0-cudnn8-devel-ubuntu18.04 /bin/bash -c nvcc --expt-relaxed-constexpr  -o ./outputs/hello ./inputs/02-cuda-hello-world-faster.cu; ./outputs/hello  \u001b[0m\u001b[97;40m Completed \u001b[0m\u001b[97;40m          \u001b[0m\u001b[97;40m /ipfs/QmSFnLwaCdoVGpyfjFZDpQ72AS5hTgzzCKmfznnVrH8SgH \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "bacalhau list --id-filter ${JOB_ID} --wide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wElIl4UYa5BO"
      },
      "source": [
        "Where it says \"Completed\", that means the job is done, and we can get the results.\n",
        "\n",
        "To find out more information about your job, run the following command:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRgrNAm7a5BO",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "bacalhau describe ${JOB_ID}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duvEDPr-a5BO",
        "outputId": "e32db07c-8fa8-4378-c44f-2cdcee03f179",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching results of job '22715ef6-759e-488a-9aa3-aaf2c8a79b08'...\n",
            "Results for job '22715ef6-759e-488a-9aa3-aaf2c8a79b08' have been written to...\n",
            "results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022/11/14 12:32:02 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 2048 kiB, got: 416 kiB). See https://github.com/lucas-clemente/quic-go/wiki/UDP-Receive-Buffer-Size for details.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "rm -rf results && mkdir -p results\n",
        "bacalhau get $JOB_ID --output-dir results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZEeFzMEa5BO"
      },
      "source": [
        "Viewing the outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhk8g_LMa5BO",
        "outputId": "100765ad-cf9a-48e1-8170-d8debea61669",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final result: 1.000000\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cat results/combined_results/stdout"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
