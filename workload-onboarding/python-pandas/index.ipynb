{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "tags": []
      },
      "source": [
        "---\n",
        "sidebar_label: \"Python Pandas\"\n",
        "sidebar_position: 6\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7JcAzJVmEau1",
        "tags": []
      },
      "source": [
        "# Running Pandas on Bacalhau\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bacalhau-project/examples/blob/main/workload-onboarding/python-pandas/index.ipynb)\n",
        "[![Open In Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/bacalhau-project/examples/HEAD?labpath=workload-onboarding/python-pandas/index.ipynb)\n",
        "[![stars - badge-generator](https://img.shields.io/github/stars/bacalhau-project/bacalhau?style=social)](https://github.com/bacalhau-project/bacalhau)\n",
        "\n",
        "### Introduction\n",
        "\n",
        "Pandas is a Python package that provides fast, flexible, and expressive data structures designed to make working with data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real-world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis/manipulation tool available in any language. It is already well on its way towards this goal.\n",
        "\n",
        "## TD;LR\n",
        "Running pandas script in Bacalhau\n",
        "\n",
        "## Prerequisite\n",
        "\n",
        "To get started, you need to install the Bacalhau client, see more information [here](https://docs.bacalhau.org/getting-started/installation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "remove_cell"
        ]
      },
      "outputs": [],
      "source": [
        "!command -v bacalhau >/dev/null 2>&1 || (export BACALHAU_INSTALL_DIR=.; curl -sL https://get.bacalhau.org/install.sh | bash)\n",
        "path=!echo $PATH\n",
        "%env PATH=./:{path[0]}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Running Pandas Locally\n",
        "\n",
        "To run Pandas script on Bacalhau for analysis, first we will place the Pandas script in a container and then run it at scale on Bacalhau. To get started, you need to install the Pandas library from pip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iD_DesnwEodT",
        "tags": [
          "remove_output"
        ]
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWsoWlxIEwPD",
        "tags": []
      },
      "source": [
        "### Importing data from CSV to DataFrame\n",
        "\n",
        "Pandas is built around the idea of a DataFrame, a container for representing data. Below you will create a DataFrame by importing a CSV file. A CSV file is a text file with one record of data per line. The values within the record are separated using the “comma” character. Pandas provides a useful method, named `read_csv()` to read the contents of the CSV file into a DataFrame. For example, we can create a file named `transactions.csv` containing details of Transactions. The CSV file is stored in the same directory that contains Python script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1217,
          "status": "ok",
          "timestamp": 1663261247850,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "t5tks1xQFMja",
        "outputId": "46aaf8a9-991f-429e-aae4-57fbd7ae7317",
        "scrolled": false,
        "tags": [
          "remove_output"
        ]
      },
      "outputs": [],
      "source": [
        "%%writefile read_csv.py\n",
        "import pandas as pd\n",
        "\n",
        "print(pd.read_csv(\"transactions.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1285,
          "status": "ok",
          "timestamp": 1663261259098,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "GFfvbdL3E18R",
        "outputId": "e53a32c6-86e4-4649-f6f8-ab4eb0d2d71e",
        "tags": [
          "remove_output"
        ]
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Downloading the dataset\n",
        "wget https://cloudflare-ipfs.com/ipfs/QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz/transactions.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1663261266498,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "U3BBfV7CFd0a",
        "outputId": "5a0248df-fadf-447e-b9e3-9bd07b26e0e0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat transactions.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmiQMOBwGaY5",
        "tags": []
      },
      "source": [
        "### Running the script\n",
        "\n",
        "Now let's run the script to read in the CSV file. The output will be a DataFrame object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 957,
          "status": "ok",
          "timestamp": 1663261342062,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "R7Y0G8L_GMse",
        "outputId": "e151de05-7acd-43b5-c79b-5b0831f23232",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                hash  ...  transaction_type\n",
            "0  0x04cbcb236043d8fb7839e07bbc7f5eed692fb2ca55d8...  ...                 0\n",
            "1  0xcea6f89720cc1d2f46cc7a935463ae0b99dd5fad9c91...  ...                 0\n",
            "2  0x463d53f0ad57677a3b430a007c1c31d15d62c37fab5e...  ...                 0\n",
            "3  0x05287a561f218418892ab053adfb3d919860988b1945...  ...                 0\n",
            "\n",
            "[4 rows x 15 columns]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "python3 read_csv.py"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcvny737Giog",
        "tags": []
      },
      "source": [
        "## Ingesting data\n",
        "\n",
        "To run pandas on Bacalhau you must store your assets in a location that Bacalhau has access to. We usually default to storing data on IPFS and code in a container, but you can also easily upload your script to IPFS too.\n",
        "\n",
        "If you are interested in finding out more about how to ingest your data into IPFS, please see the [data ingestion guide](https://docs.bacalhau.org/examples/data-ingestion/).\n",
        "\n",
        "We've already uploaded the script and data to IPFS to the following CID: `QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz`. You can look at this by browsing to one of the HTTP IPFS proxies like [ipfs.io](https://cloudflare-ipfs.com/ipfs/QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz/) or [w3s.link](https://bafybeih4hyydvojazlyv5zseelgn5u67iq2wbrbk2q4xoiw2d3cacdmzlu.ipfs.w3s.link/).\n",
        "\n",
        "## Running a Bacalhau Job\n",
        "\n",
        "After mounting the Pandas script and data from IPFS, we can now use the container for running on Bacalhau. To submit a job, run the following Bacalhau command:\n",
        "\n",
        "Now we're ready to run a Bacalhau job, whilst mounting the Pandas script and data from IPFS. We'll use the `bacalhau docker run` command to do this. The `-v` flag allows us to mount a file or directory from IPFS into the container. The `-v` flag takes two arguments, the first is the IPFS CID and the second is the path to the directory in the container. The `-v` flag can be used multiple times to mount multiple directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 653,
          "status": "ok",
          "timestamp": 1663261638758,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "uzs8k0CMGfJL",
        "outputId": "4f5d7a8e-98ee-4046-a1b3-ef221a0c6708",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%bash --out job_id\n",
        " bacalhau docker run \\\n",
        "--wait \\\n",
        "--id-only \\\n",
        "-v QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz:/files \\\n",
        "-w /files \\\n",
        "amancevice/pandas \\\n",
        "-- python read_csv.py"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Structure of the command\n",
        "\n",
        "- `bacalhau docker run`: call to bacalhau \n",
        "\n",
        "- `amancevice/pandas `: Using the official pytorch Docker image\n",
        "\n",
        "- `-v QmfKJT13h5k1b23ja3Z .....`: Mounting the uploaded dataset to path\n",
        "\n",
        "- `-u https://raw.githubusercontent.com/py..........`: Mounting our training script we will use the URL to this [Pytorch example](https://github.com/pytorch/examples/blob/main/mnist_rnn/main.py) \n",
        "\n",
        "- `-w /files` Our working directory is /outputs. This is the folder where we will to save the model as it will automatically gets uploaded to IPFS as outputs\n",
        "\n",
        "` python read_csv.py`: python script to read pandas script"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When a job is submitted, Bacalhau prints out the related `job_id`. We store that in an environment variable so that we can reuse it later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "remove_cell"
        ]
      },
      "outputs": [],
      "source": [
        "%%env JOB_ID={job_id}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "opCdYFjaHrQP",
        "tags": []
      },
      "source": [
        "## Checking the State of your Jobs\n",
        "\n",
        "- **Job status**: You can check the status of the job using `bacalhau list`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2473,
          "status": "ok",
          "timestamp": 1663261688339,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "MmLc6twCHngK",
        "outputId": "48493fed-2b8b-4085-b534-a7091bec79e4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "bacalhau list --id-filter ${JOB_ID}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mO8wG4XMH5eA",
        "tags": []
      },
      "source": [
        "When it says `Completed`, that means the job is done, and we can get the results.\n",
        "\n",
        "- **Job information**: You can find out more information about your job by using `bacalhau describe`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlzbQutAHzKi",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "bacalhau describe ${JOB_ID}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vSEblyHIIB4T",
        "tags": []
      },
      "source": [
        "When it says `Published` or `Completed`, that means the job is done, and we can get the results.\n",
        "\n",
        "- **Job information**: You can find out more information about your job by using `bacalhau describe`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Y06KRWLDIitN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "rm -rf results && mkdir -p results\n",
        "bacalhau get ${JOB_ID}  --output-dir results"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XdU_la6dJTsf",
        "tags": []
      },
      "source": [
        "## Viewing your Job Output\n",
        "\n",
        "Each job creates 3 subfolders: the **combined_results**,**per_shard files**, and the **raw** directory. To view the file, run the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1663262118236,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "bpbTMhO3INLw",
        "outputId": "a7462902-9895-418d-c123-da561a5b0d1e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "ls results/combined_results/stdout # list the contents of the current directory \n",
        "cat results/combined_results/stdout # displays the contents of the file"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPMkD4lMPwZFqll4/eh5uBe",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
