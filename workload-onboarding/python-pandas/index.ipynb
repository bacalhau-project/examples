{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "tags": []
      },
      "source": [
        "---\n",
        "sidebar_label: \"Python Pandas\"\n",
        "sidebar_position: 6\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7JcAzJVmEau1",
        "tags": []
      },
      "source": [
        "# Running Pandas on Bacalhau\n",
        "\n",
        "\n",
        "[![stars - badge-generator](https://img.shields.io/github/stars/bacalhau-project/bacalhau?style=social)](https://github.com/bacalhau-project/bacalhau)\n",
        "\n",
        "### Introduction\n",
        "\n",
        "Pandas is a Python package that provides fast, flexible, and expressive data structures designed to make working with data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real-world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis/manipulation tool available in any language. It is already well on its way towards this goal.\n",
        "\n",
        "## TD;LR\n",
        "Running pandas script in Bacalhau\n",
        "\n",
        "## Prerequisite\n",
        "\n",
        "To get started, you need to install the Bacalhau client, see more information [here](https://docs.bacalhau.org/getting-started/installation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [
          "remove_cell"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your system is linux_amd64\n",
            "\n",
            "BACALHAU CLI is detected:\n",
            "Client Version: v0.3.29\n",
            "Server Version: v0.3.29\n",
            "Reinstalling BACALHAU CLI - ./bacalhau...\n",
            "Getting the latest BACALHAU CLI...\n",
            "Installing v0.3.29 BACALHAU CLI...\n",
            "Downloading https://github.com/bacalhau-project/bacalhau/releases/download/v0.3.29/bacalhau_v0.3.29_linux_amd64.tar.gz ...\n",
            "Downloading sig file https://github.com/bacalhau-project/bacalhau/releases/download/v0.3.29/bacalhau_v0.3.29_linux_amd64.tar.gz.signature.sha256 ...\n",
            "Verified OK\n",
            "Extracting tarball ...\n",
            "NOT verifying Bin\n",
            "bacalhau installed into . successfully.\n",
            "Client Version: v0.3.29\n",
            "Server Version: v0.3.29\n",
            "env: PATH=./:/home/gitpod/.pyenv/versions/3.11.1/bin:/home/gitpod/.pyenv/libexec:/home/gitpod/.pyenv/plugins/python-build/bin:/home/gitpod/.pyenv/shims:/ide/bin/remote-cli:/home/gitpod/.nix-profile/bin:/home/gitpod/.local/bin:/home/gitpod/.sdkman/candidates/maven/current/bin:/home/gitpod/.sdkman/candidates/java/current/bin:/home/gitpod/.sdkman/candidates/gradle/current/bin:/workspace/.cargo/bin:/home/gitpod/.rvm/gems/ruby-3.2.1/bin:/home/gitpod/.rvm/gems/ruby-3.2.1@global/bin:/home/gitpod/.rvm/rubies/ruby-3.2.1/bin:/home/gitpod/.pyenv/shims:/workspace/go/bin:/home/gitpod/.nix-profile/bin:/ide/bin/remote-cli:/home/gitpod/go/bin:/home/gitpod/go-packages/bin:/home/gitpod/.nvm/versions/node/v18.16.0/bin:/home/gitpod/.yarn/bin:/home/gitpod/.pnpm:/home/gitpod/.pyenv/bin:/home/gitpod/.rvm/bin:/home/gitpod/.cargo/bin:/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin/:/home/gitpod/.local/bin:/usr/games:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/gitpod/.nvm/versions/node/v18.16.0/bin:/ide/bin/remote-cli:/home/gitpod/.nix-profile/bin:/home/gitpod/.local/bin:/home/gitpod/.sdkman/candidates/maven/current/bin:/home/gitpod/.sdkman/candidates/java/current/bin:/home/gitpod/.sdkman/candidates/gradle/current/bin:/workspace/.cargo/bin:/home/gitpod/.rvm/gems/ruby-3.2.1/bin:/home/gitpod/.rvm/gems/ruby-3.2.1@global/bin:/home/gitpod/.rvm/rubies/ruby-3.2.1/bin:/home/gitpod/.pyenv/shims:/workspace/go/bin:/home/gitpod/.nix-profile/bin:/ide/bin/remote-cli:/home/gitpod/go/bin:/home/gitpod/go-packages/bin:/home/gitpod/.nvm/versions/node/v18.16.0/bin:/home/gitpod/.yarn/bin:/home/gitpod/.pnpm:/home/gitpod/.pyenv/bin:/home/gitpod/.rvm/bin:/home/gitpod/.cargo/bin:/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin/:/home/gitpod/.local/bin:/usr/games:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/gitpod/.nvm/versions/node/v18.16.0/bin\n"
          ]
        }
      ],
      "source": [
        "!command -v bacalhau >/dev/null 2>&1 || (export BACALHAU_INSTALL_DIR=.; curl -sL https://get.bacalhau.org/install.sh | bash)\n",
        "path=!echo $PATH\n",
        "%env PATH=./:{path[0]}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Running Pandas Locally\n",
        "\n",
        "To run Pandas script on Bacalhau for analysis, first we will place the Pandas script in a container and then run it at scale on Bacalhau. To get started, you need to install the Pandas library from pip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iD_DesnwEodT",
        "tags": [
          "remove_output"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "  Using cached pandas-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "Collecting tzdata>=2022.1 (from pandas)\n",
            "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "Collecting numpy>=1.21.0 (from pandas)\n",
            "  Using cached numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Installing collected packages: pytz, tzdata, numpy, pandas\n",
            "Successfully installed numpy-1.24.3 pandas-2.0.1 pytz-2023.3 tzdata-2023.3\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWsoWlxIEwPD",
        "tags": []
      },
      "source": [
        "### Importing data from CSV to DataFrame\n",
        "\n",
        "Pandas is built around the idea of a DataFrame, a container for representing data. Below you will create a DataFrame by importing a CSV file. A CSV file is a text file with one record of data per line. The values within the record are separated using the “comma” character. Pandas provides a useful method, named `read_csv()` to read the contents of the CSV file into a DataFrame. For example, we can create a file named `transactions.csv` containing details of Transactions. The CSV file is stored in the same directory that contains Python script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1217,
          "status": "ok",
          "timestamp": 1663261247850,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "t5tks1xQFMja",
        "outputId": "46aaf8a9-991f-429e-aae4-57fbd7ae7317",
        "scrolled": false,
        "tags": [
          "remove_output"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting read_csv.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile read_csv.py\n",
        "import pandas as pd\n",
        "\n",
        "print(pd.read_csv(\"transactions.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1285,
          "status": "ok",
          "timestamp": 1663261259098,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "GFfvbdL3E18R",
        "outputId": "e53a32c6-86e4-4649-f6f8-ab4eb0d2d71e",
        "tags": [
          "remove_output"
        ]
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--2023-05-03 11:46:15--  https://cloudflare-ipfs.com/ipfs/QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz/transactions.csv\n",
            "Resolving cloudflare-ipfs.com (cloudflare-ipfs.com)... 104.17.64.14, 104.17.96.13, 2606:4700::6811:400e, ...\n",
            "Connecting to cloudflare-ipfs.com (cloudflare-ipfs.com)|104.17.64.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1567 (1.5K) [text/csv]\n",
            "Saving to: ‘transactions.csv.2’\n",
            "\n",
            "     0K .                                                     100% 21.3M=0s\n",
            "\n",
            "2023-05-03 11:46:16 (21.3 MB/s) - ‘transactions.csv.2’ saved [1567/1567]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# Downloading the dataset\n",
        "wget https://cloudflare-ipfs.com/ipfs/QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz/transactions.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1663261266498,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "U3BBfV7CFd0a",
        "outputId": "5a0248df-fadf-447e-b9e3-9bd07b26e0e0",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hash,nonce,block_hash,block_number,transaction_index,from_address,to_address,value,gas,gas_price,input,block_timestamp,max_fee_per_gas,max_priority_fee_per_gas,transaction_type\n",
            "0x04cbcb236043d8fb7839e07bbc7f5eed692fb2ca55d897f1101eac3e3ad4fab8,12,0x246edb4b351d93c27926f4649bcf6c24366e2a7c7c718dc9158eea20c03bc6ae,483920,0,0x1b63142628311395ceafeea5667e7c9026c862ca,0xf4eced2f682ce333f96f2d8966c613ded8fc95dd,0,150853,50000000000,0xa9059cbb000000000000000000000000ac4df82fe37ea2187bc8c011a23d743b4f39019a00000000000000000000000000000000000000000000000000000000000186a0,1446561880,,,0\n",
            "0xcea6f89720cc1d2f46cc7a935463ae0b99dd5fad9c91bb7357de5421511cee49,84,0x246edb4b351d93c27926f4649bcf6c24366e2a7c7c718dc9158eea20c03bc6ae,483920,1,0x9b22a80d5c7b3374a05b446081f97d0a34079e7f,0xf4eced2f682ce333f96f2d8966c613ded8fc95dd,0,150853,50000000000,0xa9059cbb00000000000000000000000066f183060253cfbe45beff1e6e7ebbe318c81e560000000000000000000000000000000000000000000000000000000000030d40,1446561880,,,0\n",
            "0x463d53f0ad57677a3b430a007c1c31d15d62c37fab5eee598551697c297c235c,88,0x246edb4b351d93c27926f4649bcf6c24366e2a7c7c718dc9158eea20c03bc6ae,483920,2,0x9df428a91ff0f3635c8f0ce752933b9788926804,0x9e669f970ec0f49bb735f20799a7e7c4a1c274e2,11000440000000000,90000,50000000000,0x,1446561880,,,0\n",
            "0x05287a561f218418892ab053adfb3d919860988b19458c570c5c30f51c146f02,20085,0x246edb4b351d93c27926f4649bcf6c24366e2a7c7c718dc9158eea20c03bc6ae,483920,3,0x2a65aca4d5fc5b5c859090a6c34d164135398226,0x743b8aeedc163c0e3a0fe9f3910d146c48e70da8,1530219620000000000,90000,50000000000,0x,1446561880,,,0"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cat transactions.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmiQMOBwGaY5",
        "tags": []
      },
      "source": [
        "### Running the script\n",
        "\n",
        "Now let's run the script to read in the CSV file. The output will be a DataFrame object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 957,
          "status": "ok",
          "timestamp": 1663261342062,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "R7Y0G8L_GMse",
        "outputId": "e151de05-7acd-43b5-c79b-5b0831f23232",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                hash  ...  transaction_type\n",
            "0  0x04cbcb236043d8fb7839e07bbc7f5eed692fb2ca55d8...  ...                 0\n",
            "1  0xcea6f89720cc1d2f46cc7a935463ae0b99dd5fad9c91...  ...                 0\n",
            "2  0x463d53f0ad57677a3b430a007c1c31d15d62c37fab5e...  ...                 0\n",
            "3  0x05287a561f218418892ab053adfb3d919860988b1945...  ...                 0\n",
            "\n",
            "[4 rows x 15 columns]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "python3 read_csv.py"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcvny737Giog",
        "tags": []
      },
      "source": [
        "## Ingesting data\n",
        "\n",
        "To run pandas on Bacalhau you must store your assets in a location that Bacalhau has access to. We usually default to storing data on IPFS and code in a container, but you can also easily upload your script to IPFS too.\n",
        "\n",
        "If you are interested in finding out more about how to ingest your data into IPFS, please see the [data ingestion guide](https://docs.bacalhau.org/examples/data-ingestion/).\n",
        "\n",
        "We've already uploaded the script and data to IPFS to the following CID: `QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz`. You can look at this by browsing to one of the HTTP IPFS proxies like [ipfs.io](https://cloudflare-ipfs.com/ipfs/QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz/) or [w3s.link](https://bafybeih4hyydvojazlyv5zseelgn5u67iq2wbrbk2q4xoiw2d3cacdmzlu.ipfs.w3s.link/).\n",
        "\n",
        "## Running a Bacalhau Job\n",
        "\n",
        "After mounting the Pandas script and data from IPFS, we can now use the container for running on Bacalhau. To submit a job, run the following Bacalhau command:\n",
        "\n",
        "Now we're ready to run a Bacalhau job, whilst mounting the Pandas script and data from IPFS. We'll use the `bacalhau docker run` command to do this. The `-v` flag allows us to mount a file or directory from IPFS into the container. The `-v` flag takes two arguments, the first is the IPFS CID and the second is the path to the directory in the container. The `-v` flag can be used multiple times to mount multiple directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 653,
          "status": "ok",
          "timestamp": 1663261638758,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "uzs8k0CMGfJL",
        "outputId": "4f5d7a8e-98ee-4046-a1b3-ef221a0c6708",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%bash --out job_id\n",
        "bacalhau docker run \\\n",
        "    --wait \\\n",
        "    --id-only \\\n",
        "    -i ipfs://QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz:/files \\\n",
        "    -w /files \\\n",
        "    amancevice/pandas \\\n",
        "    -- python read_csv.py"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Structure of the command\n",
        "\n",
        "- `bacalhau docker run`: call to bacalhau \n",
        "\n",
        "- `amancevice/pandas `: Using the official pytorch Docker image\n",
        "\n",
        "- ``-i ipfs://QmfKJT13h5k1b23ja3Z .....`: Mounting the uploaded dataset to path\n",
        "\n",
        "- `-w /files` Our working directory is /outputs. This is the folder where we will to save the model as it will automatically gets uploaded to IPFS as outputs\n",
        "\n",
        "` python read_csv.py`: python script to read pandas script"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When a job is submitted, Bacalhau prints out the related `job_id`. We store that in an environment variable so that we can reuse it later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "tags": [
          "remove_cell"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: JOB_ID=61e542a7-bea1-4382-b3c9-40050d143ad6\n"
          ]
        }
      ],
      "source": [
        "%env JOB_ID={job_id}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "opCdYFjaHrQP",
        "tags": []
      },
      "source": [
        "## Checking the State of your Jobs\n",
        "\n",
        "- **Job status**: You can check the status of the job using `bacalhau list`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2473,
          "status": "ok",
          "timestamp": 1663261688339,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "MmLc6twCHngK",
        "outputId": "48493fed-2b8b-4085-b534-a7091bec79e4",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92;100m CREATED  \u001b[0m\u001b[92;100m ID       \u001b[0m\u001b[92;100m JOB                     \u001b[0m\u001b[92;100m STATE     \u001b[0m\u001b[92;100m VERIFIED \u001b[0m\u001b[92;100m PUBLISHED               \u001b[0m\n",
            "\u001b[97;40m 11:46:26 \u001b[0m\u001b[97;40m 61e542a7 \u001b[0m\u001b[97;40m Docker amancevice/pa... \u001b[0m\u001b[97;40m Completed \u001b[0m\u001b[97;40m          \u001b[0m\u001b[97;40m ipfs://QmY2MEETWyX77... \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "bacalhau list --id-filter ${JOB_ID}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mO8wG4XMH5eA",
        "tags": []
      },
      "source": [
        "When it says `Completed`, that means the job is done, and we can get the results.\n",
        "\n",
        "- **Job information**: You can find out more information about your job by using `bacalhau describe`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GlzbQutAHzKi",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job:\n",
            "  APIVersion: V1beta1\n",
            "  Metadata:\n",
            "    ClientID: 07bde6e8241b19d58c1c5ff3e8ec17e1e80ac6424cd029bd1317a60f1705b583\n",
            "    CreatedAt: \"2023-05-03T11:46:26.767484787Z\"\n",
            "    ID: 61e542a7-bea1-4382-b3c9-40050d143ad6\n",
            "    Requester:\n",
            "      RequesterNodeID: QmdZQ7ZbhnvWY1J12XYKGHApJ6aufKyLNSvf8jZBrBaAVL\n",
            "      RequesterPublicKey: CAASpgIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDVRKPgCfY2fgfrkHkFjeWcqno+MDpmp8DgVaY672BqJl/dZFNU9lBg2P8Znh8OTtHPPBUBk566vU3KchjW7m3uK4OudXrYEfSfEPnCGmL6GuLiZjLf+eXGEez7qPaoYqo06gD8ROdD8VVse27E96LlrpD1xKshHhqQTxKoq1y6Rx4DpbkSt966BumovWJ70w+Nt9ZkPPydRCxVnyWS1khECFQxp5Ep3NbbKtxHNX5HeULzXN5q0EQO39UN6iBhiI34eZkH7PoAm3Vk5xns//FjTAvQw6wZUu8LwvZTaihs+upx2zZysq6CEBKoeNZqed9+Tf+qHow0P5pxmiu+or+DAgMBAAE=\n",
            "  Spec:\n",
            "    Deal:\n",
            "      Concurrency: 1\n",
            "    Docker:\n",
            "      Entrypoint:\n",
            "      - python\n",
            "      - read_csv.py\n",
            "      Image: amancevice/pandas\n",
            "      WorkingDirectory: /files\n",
            "    Engine: Docker\n",
            "    Language:\n",
            "      JobContext: {}\n",
            "    Network:\n",
            "      Type: None\n",
            "    Publisher: Estuary\n",
            "    PublisherSpec:\n",
            "      Type: Estuary\n",
            "    Resources:\n",
            "      GPU: \"\"\n",
            "    Timeout: 1800\n",
            "    Verifier: Noop\n",
            "    Wasm:\n",
            "      EntryModule: {}\n",
            "    inputs:\n",
            "    - CID: QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz\n",
            "      Name: ipfs://QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz\n",
            "      StorageSource: IPFS\n",
            "      path: /files\n",
            "    outputs:\n",
            "    - Name: outputs\n",
            "      StorageSource: IPFS\n",
            "      path: /outputs\n",
            "State:\n",
            "  CreateTime: \"2023-05-03T11:46:26.767504591Z\"\n",
            "  Executions:\n",
            "  - AcceptedAskForBid: true\n",
            "    ComputeReference: e-37a9de63-8bf2-4d83-932f-29fdf98c5274\n",
            "    CreateTime: \"2023-05-03T11:46:35.551431968Z\"\n",
            "    JobID: 61e542a7-bea1-4382-b3c9-40050d143ad6\n",
            "    NodeId: QmYgxZiySj3MRkwLSL4X2MF5F9f2PMhAE3LV49XkfNL1o3\n",
            "    PublishedResults:\n",
            "      CID: QmY2MEETWyX77BBYBNBpUW5bjkVAyP87EotPDVW2vjHG8K\n",
            "      Name: ipfs://QmY2MEETWyX77BBYBNBpUW5bjkVAyP87EotPDVW2vjHG8K\n",
            "      StorageSource: IPFS\n",
            "    RunOutput:\n",
            "      exitCode: 0\n",
            "      runnerError: \"\"\n",
            "      stderr: \"\"\n",
            "      stderrtruncated: false\n",
            "      stdout: |2\n",
            "                                                        hash  ...  transaction_type\n",
            "        0  0x04cbcb236043d8fb7839e07bbc7f5eed692fb2ca55d8...  ...                 0\n",
            "        1  0xcea6f89720cc1d2f46cc7a935463ae0b99dd5fad9c91...  ...                 0\n",
            "        2  0x463d53f0ad57677a3b430a007c1c31d15d62c37fab5e...  ...                 0\n",
            "        3  0x05287a561f218418892ab053adfb3d919860988b1945...  ...                 0\n",
            "\n",
            "        [4 rows x 15 columns]\n",
            "      stdouttruncated: false\n",
            "    State: Completed\n",
            "    UpdateTime: \"2023-05-03T11:46:35.543450963Z\"\n",
            "    VerificationResult:\n",
            "      Complete: true\n",
            "      Result: true\n",
            "    Version: 6\n",
            "  - AcceptedAskForBid: true\n",
            "    ComputeReference: e-1f8a0747-bf6d-49c2-973c-35dfb957448b\n",
            "    CreateTime: \"2023-05-03T11:46:27.267720744Z\"\n",
            "    JobID: 61e542a7-bea1-4382-b3c9-40050d143ad6\n",
            "    NodeId: QmXaXu9N5GNetatsvwnTfQqNtSeKAD6uCmarbh3LMRYAcF\n",
            "    PublishedResults: {}\n",
            "    State: BidRejected\n",
            "    UpdateTime: \"2023-05-03T11:46:27.267494495Z\"\n",
            "    VerificationResult: {}\n",
            "    Version: 3\n",
            "  - AcceptedAskForBid: true\n",
            "    ComputeReference: e-8c1c582c-9994-4f87-ba57-746965532790\n",
            "    CreateTime: \"2023-05-03T11:46:28.584477348Z\"\n",
            "    JobID: 61e542a7-bea1-4382-b3c9-40050d143ad6\n",
            "    NodeId: QmUDAXvv31WPZ8U9CzuRTMn9iFGiopGE7rHiah1X8a6PkT\n",
            "    PublishedResults: {}\n",
            "    State: BidRejected\n",
            "    UpdateTime: \"2023-05-03T11:46:28.5840629Z\"\n",
            "    VerificationResult: {}\n",
            "    Version: 3\n",
            "  JobID: 61e542a7-bea1-4382-b3c9-40050d143ad6\n",
            "  State: Completed\n",
            "  TimeoutAt: \"0001-01-01T00:00:00Z\"\n",
            "  UpdateTime: \"2023-05-03T11:46:35.551464593Z\"\n",
            "  Version: 5\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "bacalhau describe ${JOB_ID}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vSEblyHIIB4T",
        "tags": []
      },
      "source": [
        "When it says `Published` or `Completed`, that means the job is done, and we can get the results.\n",
        "\n",
        "- **Job information**: You can find out more information about your job by using `bacalhau describe`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Y06KRWLDIitN",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching results of job '61e542a7-bea1-4382-b3c9-40050d143ad6'...\n",
            "\n",
            "Computing default go-libp2p Resource Manager limits based on:\n",
            "    - 'Swarm.ResourceMgr.MaxMemory': \"34 GB\"\n",
            "    - 'Swarm.ResourceMgr.MaxFileDescriptors': 524288\n",
            "\n",
            "Applying any user-supplied overrides on top.\n",
            "Run 'ipfs swarm limit all' to see the resulting limits.\n",
            "\n",
            "Results for job '61e542a7-bea1-4382-b3c9-40050d143ad6' have been written to...\n",
            "results\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "rm -rf results && mkdir -p results\n",
        "bacalhau get ${JOB_ID}  --output-dir results"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XdU_la6dJTsf",
        "tags": []
      },
      "source": [
        "## Viewing your Job Output\n",
        "\n",
        "Each job creates 3 subfolders: the **combined_results**,**per_shard files**, and the **raw** directory. To view the file, run the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1663262118236,
          "user": {
            "displayName": "Vedant Padwal",
            "userId": "05534807475078682627"
          },
          "user_tz": -330
        },
        "id": "bpbTMhO3INLw",
        "outputId": "a7462902-9895-418d-c123-da561a5b0d1e",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                hash  ...  transaction_type\n",
            "0  0x04cbcb236043d8fb7839e07bbc7f5eed692fb2ca55d8...  ...                 0\n",
            "1  0xcea6f89720cc1d2f46cc7a935463ae0b99dd5fad9c91...  ...                 0\n",
            "2  0x463d53f0ad57677a3b430a007c1c31d15d62c37fab5e...  ...                 0\n",
            "3  0x05287a561f218418892ab053adfb3d919860988b1945...  ...                 0\n",
            "\n",
            "[4 rows x 15 columns]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cat results/job_id/stdout # displays the contents of the file"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPMkD4lMPwZFqll4/eh5uBe",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
