<!-- Generated by SpecStory -->

# SQLite to Databricks Upload Error (2025-05-27 18:27:10)

_**User**_

❯ uv run -s sqlite_to_databricks_uploader.py --config ../databricks-uploader-config.yaml
Reading inline script metadata from `sqlite_to_databricks_uploader.py`
2025-05-27 18:26:52,353 INFO Detected SQLite table: sensor_readings
2025-05-27 18:26:52,353 INFO Using user-supplied timestamp column for SQLite table 'sensor_readings': timestamp
2025-05-27 18:26:52,353 INFO Starting continuous upload every 300 seconds, initial timestamp=2025-05-27 01:33:55.398000+00:00
2025-05-27 18:26:54,051 INFO sanitize_config not provided. Using default {{}}.
2025-05-27 18:26:54,051 INFO filter_config not provided. Using default {{}}.
2025-05-27 18:26:54,051 INFO aggregate_config not provided. Using default {{}}.
2025-05-27 18:26:55,464 INFO Received status code 200 for POST request
2025-05-27 18:26:55,464 INFO HTTP Response with status code 200, message: OK
2025-05-27 18:26:55,465 INFO Successfully opened session 01f03b62-d72c-1b57-95db-a3a7a02a774a
2025-05-27 18:26:55,466 INFO Successfully connected to Databricks: https://dbc-14f633f9-8e16.cloud.databricks.com
2025-05-27 18:26:55,466 ERROR Error during Databricks upload: type object 'ParamEscaper' has no attribute 'escape_path'
Traceback (most recent call last):
  File "/Users/daaronch/code/bacalhau-examples/data-engineering/databricks-with-bacalhau/databricks-uploader/sqlite_to_databricks_uploader.py", line 572, in main
    f"USE {ParamEscaper.escape_path(databricks_database)}"
           ^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ParamEscaper' has no attribute 'escape_path'. Did you mean: 'escape_args'?
2025-05-27 18:26:55,469 INFO Closing session 01f03b62-d72c-1b57-95db-a3a7a02a774a
2025-05-27 18:26:55,823 INFO Received status code 200 for POST request
2025-05-27 18:26:55,823 INFO HTTP Response with status code 200, message: OK
2025-05-27 18:26:55,824 INFO Databricks connection closed.
2025-05-27 18:26:55,824 WARNING Upload to Databricks failed or was incomplete. State timestamp will not be updated.
^CTraceback (most recent call last):
  File "/Users/daaronch/code/bacalhau-examples/data-engineering/databricks-with-bacalhau/databricks-uploader/sqlite_to_databricks_uploader.py", line 653, in <module>
    main()
  File "/Users/daaronch/code/bacalhau-examples/data-engineering/databricks-with-bacalhau/databricks-uploader/sqlite_to_databricks_uploader.py", line 649, in main
    time.sleep(interval)
KeyboardInterrupt

╭─   ~/c/bacalhau-examples/data-e/databricks-with-bacalhau/databricks-uploader   feat/local-processing-uploader ⇡1 *1 !5 ?2 ────────────────────  9s ▼
╰─❯

---

_**Assistant**_



---

Okay, I see the `AttributeError`. It seems the method `escape_path` was removed or renamed in the `databricks-sql-connector` library. The error message itself suggests `escape_args`, but for escaping database and table names, `escape_identifier` is the more appropriate method.

I'll correct this by replacing all instances of `ParamEscaper.escape_path` with `ParamEscaper.escape_identifier` in your `sqlite_to_databricks_uploader.py` file.



---

```diff
                  # Set current database
                  cursor_db_query.execute(
-                     f"USE {ParamEscaper.escape_path(databricks_database)}"
+                     f"USE {ParamEscaper.escape_identifier(databricks_database)}"
                  )
                  logging.info(f"Using database: {databricks_database}")
  
                  print(f"\n--- Tables in Database '{databricks_database}' ---")
                  cursor_db_query.execute(
-                     f"SHOW TABLES IN {ParamEscaper.escape_path(databricks_database)}"
+                     f"SHOW TABLES IN {ParamEscaper.escape_identifier(databricks_database)}"
                  )
                  print_query_results(cursor_db_query)
  
-                 qualified_table_name = f"{ParamEscaper.escape_path(databricks_database)}.{ParamEscaper.escape_path(databricks_table)}"
+                 qualified_table_name = f"{ParamEscaper.escape_identifier(databricks_database)}.{ParamEscaper.escape_identifier(databricks_table)}"
                  print(f"\n--- Description for Table '{qualified_table_name}' ---")
                  cursor_db_query.execute(
```

```diff
                  try:
                      cursor_db_query.execute(
-                         f"USE {ParamEscaper.escape_path(databricks_database)}"
+                         f"USE {ParamEscaper.escape_identifier(databricks_database)}"
                      )
                      logging.info(f"Ensured database context: {databricks_database}")
```

```diff
                          # Set current database
                          cursor_db.execute(
-                             f"USE {ParamEscaper.escape_path(databricks_database)}"
+                             f"USE {ParamEscaper.escape_identifier(databricks_database)}"
                          )
                          logging.info(f"Using database: {databricks_database}")
  
                          # Prepare for batch insert
-                         table_name_qualified = f"{ParamEscaper.escape_path(databricks_database)}.{ParamEscaper.escape_path(databricks_table)}"
+                         table_name_qualified = f"{ParamEscaper.escape_identifier(databricks_database)}.{ParamEscaper.escape_identifier(databricks_table)}"
  
                          columns = [
```

---

The `AttributeError` should now be resolved. I've replaced `ParamEscaper.escape_path` with `ParamEscaper.escape_identifier` in the relevant sections of your script.

You can try running your command again:
`uv run -s sqlite_to_databricks_uploader.py --config ../databricks-uploader-config.yaml`

---

