{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fc12ae14-aa9c-48e9-843e-3421f39d5db3",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: 'Image Processing'\n",
    "sidebar_position: 1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e293cb-1bfd-4f42-9eb7-59f57d548202",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Often, you will need to process a number of images across an entire data set hosted on IPFS. For example, the entire [Landsat data dataset is hosted on IPFS ](https://ipfs.io/ipfs/QmeZRGhe4PmjctYVSVHuEiA9oSXnqmYa4kQubSHgWbjv72). This is many thousands of images, it would be very convenient to run a job against the data without having to download it!\n",
    "\n",
    "This page is a demo of a data intensive image processing workload run on Bacalhau that transforms very high resolution imagery into thumbnail-size pictures.\n",
    "It is an example of a highly parellizable compute task where a resize function is applied over a large number of files.\n",
    "For a live walk through of this demo please watch the first part of the video below, otherwise feel free to run the demo yourself by following the steps below.\n",
    "\n",
    "[![Bacalhau Intro Video](/img/Bacalhau_Intro_Video_thumbnail.jpg)](https://www.youtube.com/watch?v=wkOh05J5qgA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41897077-837a-40e3-9927-032a55bebbb6",
   "metadata": {},
   "source": [
    "## Prerequistes\n",
    "\n",
    "Make sure you have the latest `bacalhau` client installed by following the [getting started instructions](../../../getting-started/installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20645a31-280a-4117-acd0-199eab0e3081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Version: v0.2.3\n",
      "Server Version: v0.2.3\n"
     ]
    }
   ],
   "source": [
    "!bacalhau version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcf72e6-acf8-4ff8-807d-8d5d72168bee",
   "metadata": {},
   "source": [
    "## Submit the workload\n",
    "\n",
    "In this example we will be working against a small [subset of the dataset](https://ipfs.io/ipfs/QmeZRGhe4PmjctYVSVHuEiA9oSXnqmYa4kQubSHgWbjv72). We will go through a demo similar to what you may need to do at scale: resizing all the images down to 100x100px.\n",
    "\n",
    "To get started with a new concept, `bacalhau docker run` allows you to pass input data volume with a `-v CID:path` argument just like Docker, except the left hand side of the argument is a [content identifier (CID)](https://github.com/multiformats/cid).\n",
    "This results in a *data volume* and can mount in an entire directory (instead of a single file).\n",
    "\n",
    "When you set this flag, it then ensures that CID is mounted into the container at the `path` location as an input volume.\n",
    "\n",
    "Data volumes also work on output - by default `bacalhau docker run` always creates an output data volume mounted at `/outputs`.\n",
    "This is a convenient location to store the results of your job. See below for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679c8e24-a566-4895-a899-1617c9d2500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9536e23c-4a1e-4e73-a85a-3e81101f26d4\n"
     ]
    }
   ],
   "source": [
    "!bacalhau docker run \\\n",
    "  -v QmeZRGhe4PmjctYVSVHuEiA9oSXnqmYa4kQubSHgWbjv72:/input_images \\\n",
    "  dpokidov/imagemagick:7.1.0-47-ubuntu \\\n",
    "  -- magick mogrify -resize 100x100 -quality 100 -path /outputs '/input_images/*.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daca7555-78a7-49bb-9db4-7671679c3263",
   "metadata": {},
   "source": [
    "The job has been submitted and Bacalhau has printed out the related job id.\n",
    "We store that in an environment variable so that we can reuse it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b265396-83d9-43d1-9d06-ab8f9bdb7533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOB_ID=9536e23c\n",
      "\u001b[92;100m CREATED  \u001b[0m\u001b[92;100m ID       \u001b[0m\u001b[92;100m JOB                     \u001b[0m\u001b[92;100m STATE     \u001b[0m\u001b[92;100m VERIFIED \u001b[0m\u001b[92;100m PUBLISHED               \u001b[0m\n",
      "\u001b[97;40m 15:11:16 \u001b[0m\u001b[97;40m 9536e23c \u001b[0m\u001b[97;40m Docker dpokidov/imag... \u001b[0m\u001b[97;40m Published \u001b[0m\u001b[97;40m          \u001b[0m\u001b[97;40m /ipfs/bafybeidtitnyf... \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%env JOB_ID=9536e23c\n",
    "!bacalhau list --id-filter=${JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d3b052-8435-410a-9bdf-cca66aa3c5ab",
   "metadata": {},
   "source": [
    "Since the job state is published/complete, the job result can be downloaded locally.\n",
    "We achieve that in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b60416-57d7-4fd2-9fd7-1c9920f0ad56",
   "metadata": {},
   "source": [
    "## Get results\n",
    "\n",
    "First, let us create a new directory that will store our job outputs.\n",
    "Second, use the `get` verb to download the job outputs into the current directory.\n",
    "_This command prints out a number of verbose logs, although these meant for Bacalhau developers you may want to ignore them (this will soon: [issue #614](https://github.com/filecoin-project/bacalhau/issues/614))._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebdfe481-b430-426f-8fb3-fe0bfce513e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m17:15:26.617 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mbacalhau/get.go:67\u001b[0m\u001b[36m >\u001b[0m Fetching results of job '9536e23c'...\n",
      "\u001b[90m17:15:30.609 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mipfs/downloader.go:115\u001b[0m\u001b[36m >\u001b[0m Found 1 result shards, downloading to temporary folder.\n",
      "\u001b[90m17:15:37.696 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mipfs/downloader.go:195\u001b[0m\u001b[36m >\u001b[0m Combining shard from output volume 'outputs' to final location: '/tmp/img-demo'\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /tmp/img-demo\n",
    "!bacalhau get ${JOB_ID} --output-dir /tmp/img-demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e80386-a0d7-4320-b0b1-4c2622b66db6",
   "metadata": {},
   "source": [
    "Now, the docker run command above used the `outputs` volume as a results folder so when we download them they will be stored in a homonymous folder within `volumes/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf6819af-def3-47f7-ae99-e6d191b1e832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 384\n",
      "-rw-r--r--  1 enricorotundo  staff  14536 Sep 14 17:15 cafires_vir_2021231_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  34594 Sep 14 17:15 greatsaltlake_oli_2017210_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  12928 Sep 14 17:15 greecefires_oli_2021222_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  16705 Sep 14 17:15 haitiearthquake_oli_20212_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  42427 Sep 14 17:15 iwojima_tmo_2021225_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  10419 Sep 14 17:15 lakemead_etm_2000220_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  13467 Sep 14 17:15 lapalma_oli_2021141_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  13687 Sep 14 17:15 spainfire_oli_2021227_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  15476 Sep 14 17:15 sulphursprings_oli_2019254_lrg.jpg\n"
     ]
    }
   ],
   "source": [
    "ls -l /tmp/img-demo/volumes/outputs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce0286-7715-4a10-9b3b-fa5f9e7aa6fc",
   "metadata": {},
   "source": [
    "## Where to go next?\n",
    "\n",
    "* [How to run an existing workload on Bacalhau](../../../getting-started/workload-onboarding).\n",
    "* [Check out the Bacalhau CLI Reference page](../../../all-flags)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e80f7b1-e600-454b-bec6-d27a3ffd9f67",
   "metadata": {},
   "source": [
    "## Support\n",
    "\n",
    "Please reach out to the [Bacalhau team via Slack](https://filecoinproject.slack.com/archives/C02RLM3JHUY) to seek help or in case of any issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
