{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fc12ae14-aa9c-48e9-843e-3421f39d5db3",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: 'Image Processing'\n",
    "sidebar_position: 1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e293cb-1bfd-4f42-9eb7-59f57d548202",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Often, you will need to process a number of images across an entire data set hosted on IPFS. For example, the entire [Landsat data dataset is hosted on IPFS ](https://ipfs.io/ipfs/QmeZRGhe4PmjctYVSVHuEiA9oSXnqmYa4kQubSHgWbjv72). This is many thousands of images, it would be very convenient to run a job against the data without having to download it!\n",
    "\n",
    "This page is a demo of a data intensive image processing workload run on Bacalhau that transforms very high resolution imagery into thumbnail-size pictures.\n",
    "It is an example of a highly parallelizable compute task where a resize function is applied over a large number of files.\n",
    "For a live walk through of this demo please watch the first part of the video below, otherwise feel free to run the demo yourself by following the steps below.\n",
    "\n",
    "[![Bacalhau Intro Video](/img/Bacalhau_Intro_Video_thumbnail.jpg)](https://www.youtube.com/watch?v=wkOh05J5qgA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41897077-837a-40e3-9927-032a55bebbb6",
   "metadata": {},
   "source": [
    "## Prerequistes\n",
    "\n",
    "Make sure you have the latest `bacalhau` client installed by following the [getting started instructions](../../../getting-started/installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20645a31-280a-4117-acd0-199eab0e3081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Version: v0.2.3\n",
      "Server Version: v0.2.3\n"
     ]
    }
   ],
   "source": [
    "!bacalhau version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcf72e6-acf8-4ff8-807d-8d5d72168bee",
   "metadata": {},
   "source": [
    "## Submit the workload\n",
    "\n",
    "In this example we will be working against a small [subset of the dataset](https://ipfs.io/ipfs/QmeZRGhe4PmjctYVSVHuEiA9oSXnqmYa4kQubSHgWbjv72). We will go through a demo similar to what you may need to do at scale: resizing all the images down to 100x100px.\n",
    "\n",
    "To get started with a new concept, `bacalhau docker run` allows you to pass input data volume with a `-v CID:path` argument just like Docker, except the left hand side of the argument is a [content identifier (CID)](https://github.com/multiformats/cid).\n",
    "This results in a *data volume* and can mount in an entire directory (instead of a single file).\n",
    "\n",
    "When you set this flag, it then ensures that CID is mounted into the container at the `path` location as an input volume.\n",
    "\n",
    "Data volumes also work on output - by default `bacalhau docker run` always creates an output data volume mounted at `/outputs`.\n",
    "This is a convenient location to store the results of your job. See below for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679c8e24-a566-4895-a899-1617c9d2500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4d49f48a-0522-4016-aa0a-23168d1ca99a\n"
     ]
    }
   ],
   "source": [
    "!bacalhau docker run \\\n",
    "  -v QmeZRGhe4PmjctYVSVHuEiA9oSXnqmYa4kQubSHgWbjv72:/input_images \\\n",
    "  dpokidov/imagemagick:7.1.0-47-ubuntu \\\n",
    "  -- magick mogrify -resize 100x100 -quality 100 -path /outputs '/input_images/*.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daca7555-78a7-49bb-9db4-7671679c3263",
   "metadata": {},
   "source": [
    "The job has been submitted and Bacalhau has printed out the related job id.\n",
    "We store that in an environment variable so that we can reuse it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b265396-83d9-43d1-9d06-ab8f9bdb7533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOB_ID=4d49f48a\n",
      " CREATED   ID        JOB                      STATE      VERIFIED  PUBLISHED               \n",
      " 11:33:22  4d49f48a  Docker dpokidov/imag...  Published            /ipfs/bafybeidtitnyf... \n"
     ]
    }
   ],
   "source": [
    "%env JOB_ID=4d49f48a\n",
    "!bacalhau list --id-filter=${JOB_ID} --no-style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d3b052-8435-410a-9bdf-cca66aa3c5ab",
   "metadata": {},
   "source": [
    "Since the job state is published/complete, the job result can be downloaded locally.\n",
    "We achieve that in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b60416-57d7-4fd2-9fd7-1c9920f0ad56",
   "metadata": {},
   "source": [
    "## Get results\n",
    "\n",
    "First, let us create a new directory that will store our job outputs.\n",
    "Second, use the `get` verb to download the job outputs into the directory specified by the `--output-dir` argument.\n",
    "_Please ignore the `> /dev/null 2>&1` portion of the command, it is there only temporarily until we fix this [issue #614](https://github.com/filecoin-project/bacalhau/issues/614) and is meant to supress debug logs that are not useful for the user._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebdfe481-b430-426f-8fb3-fe0bfce513e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /tmp/img-demo\n",
    "!bacalhau get ${JOB_ID} --output-dir /tmp/img-demo > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e80386-a0d7-4320-b0b1-4c2622b66db6",
   "metadata": {},
   "source": [
    "Now, the docker run command above used the `outputs` volume as a results folder so when we download them they will be stored in a homonymous folder within `volumes/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6819af-def3-47f7-ae99-e6d191b1e832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 384\n",
      "-rw-r--r--  1 enricorotundo  staff  14536 Sep 15 13:42 cafires_vir_2021231_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  34594 Sep 15 13:42 greatsaltlake_oli_2017210_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  12928 Sep 15 13:42 greecefires_oli_2021222_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  16705 Sep 15 13:42 haitiearthquake_oli_20212_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  42427 Sep 15 13:42 iwojima_tmo_2021225_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  10419 Sep 15 13:42 lakemead_etm_2000220_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  13467 Sep 15 13:42 lapalma_oli_2021141_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  13687 Sep 15 13:42 spainfire_oli_2021227_lrg.jpg\n",
      "-rw-r--r--  1 enricorotundo  staff  15476 Sep 15 13:42 sulphursprings_oli_2019254_lrg.jpg\n"
     ]
    }
   ],
   "source": [
    "ls -l /tmp/img-demo/volumes/outputs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce0286-7715-4a10-9b3b-fa5f9e7aa6fc",
   "metadata": {},
   "source": [
    "## Where to go next?\n",
    "\n",
    "* [How to run an existing workload on Bacalhau](../../../getting-started/workload-onboarding).\n",
    "* [Check out the Bacalhau CLI Reference page](../../../all-flags)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e80f7b1-e600-454b-bec6-d27a3ffd9f67",
   "metadata": {},
   "source": [
    "## Support\n",
    "\n",
    "Please reach out to the [Bacalhau team via Slack](https://filecoinproject.slack.com/archives/C02RLM3JHUY) to seek help or in case of any issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
