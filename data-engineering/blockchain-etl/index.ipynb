{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_label: BlockchainETL\n",
        "sidebar_position: 3\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bacalhau-project/examples/blob/main/data-engineering/blockchain-etl/index.ipynb)\n",
        "[![Open In Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/bacalhau-project/examples/HEAD?labpath=data-engineering/blockchain-etl/index.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkXV6QLvygma"
      },
      "source": [
        "# BlockchainETL\n",
        "\n",
        "\n",
        "# **Introduction**\n",
        "\n",
        "Analyzing and loading blockchain data can be difficult since loading blockchain ledgers can be hard to do since downloading them for performing ETL can be difficult as well tricky, since the datasets are on IPFS we could mount the CIDs and then analyze the performing ETL operations on that data can be made easier to do it at scale,[ Ethereum ETL](https://ethereum-etl.readthedocs.io/en/latest/) lets you convert blockchain data into convenient formats like CSVs and relational databases.\n",
        "\n",
        "Prerequisites\n",
        "\n",
        "\n",
        "\n",
        "* Python 3 running locally - [Installation Binaries](http://here) / [Tutorial](https://realpython.com/installing-python/)\n",
        "* The Bacalhau client - [Installation instructions](https://docs.bacalhau.org/getting-started/installation)\n",
        "* (Optional, but Recommended) Docker - [Installation Instructions](https://docs.docker.com/get-docker/)\n",
        "\n",
        "\n",
        "# **Running EthereumETL locally**\n",
        "\n",
        "Downloading Datasets\n",
        "\n",
        "Data could be downloaded using tools like [Geth Documentation | Go Ethereum](https://geth.ethereum.org/docs/) and then you can upload it to IPFS or better use the dataset already there on IPFS link to the dataset used   \n",
        "\n",
        "For this example you can use this CSV file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGscZGDFyUJC",
        "outputId": "ab40753d-83a9-4c2f-91e8-42f959862d26",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-10-03 04:44:33--  https://cloudflare-ipfs.com/ipfs/QmTAQMGiSv9xocaB4PUCT5nSBHrf9HZrYj21BAZ5nMTY2W/transactions.csv\n",
            "Resolving cloudflare-ipfs.com (cloudflare-ipfs.com)... 104.17.96.13, 104.17.64.14, 2606:4700::6811:400e, ...\n",
            "Connecting to cloudflare-ipfs.com (cloudflare-ipfs.com)|104.17.96.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1567 (1.5K) [text/csv]\n",
            "Saving to: ‘transactions.csv’\n",
            "\n",
            "transactions.csv    100%[===================>]   1.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-10-03 04:44:34 (21.5 MB/s) - ‘transactions.csv’ saved [1567/1567]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "wget https://cloudflare-ipfs.com/ipfs/QmTAQMGiSv9xocaB4PUCT5nSBHrf9HZrYj21BAZ5nMTY2W/transactions.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoxWwqTtynX8"
      },
      "source": [
        "\n",
        "Create a folder called ‘outputs’ for the output dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9acyzEIyo-h",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        " mkdir outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2RNEwPjyr00"
      },
      "source": [
        "Installing the ethreumetl package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uugWSqGysqL",
        "outputId": "5bdcd741-3ca9-4e93-b1d9-bde7657f65fa",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        " pip install ethereum-etl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvG-Nf1lzFwH"
      },
      "source": [
        "\n",
        "Run the following command  for Extracting transaction hashes from `transactions.csv`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49q7UtSWzI_G",
        "outputId": "d2b7a49d-3d34-4961-b38f-f9e93d5dccf9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        " ethereumetl extract_csv_column --input transactions.csv --column hash --output ./output/transaction_hashes.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86n2UzMGzPlv"
      },
      "source": [
        "\n",
        "Source [Commands - Ethereum ETL](https://ethereum-etl.readthedocs.io/en/latest/commands/) For running other commands\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCCfxjBRzTzQ",
        "outputId": "3dd165db-7138-4645-d4ab-a1a76ad7b715",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0x04cbcb236043d8fb7839e07bbc7f5eed692fb2ca55d897f1101eac3e3ad4fab8\n",
            "0xcea6f89720cc1d2f46cc7a935463ae0b99dd5fad9c91bb7357de5421511cee49\n",
            "0x463d53f0ad57677a3b430a007c1c31d15d62c37fab5eee598551697c297c235c\n",
            "0x05287a561f218418892ab053adfb3d919860988b19458c570c5c30f51c146f02\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        " cat output/transaction_hashes.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYWVyCrLzZHu"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## **Creating a docker container**\n",
        "\n",
        "In this step you will create a  `Dockerfile` to create your Docker deployment. The `Dockerfile` is a text document that contains the commands used to assemble the image.\n",
        "\n",
        "First, create the `Dockerfile`.\n",
        "\n",
        "Next, add your desired configuration to the `Dockerfile`. These commands specify how the image will be built, and what extra requirements will be included.\n",
        "\n",
        "\n",
        "```\n",
        "FROM python:3.8\n",
        "\n",
        "RUN pip install ethereum-etl\n",
        "```\n",
        "\n",
        "\n",
        "We create a simple python container with just installing the single package [Ethereum ETL](https://ethereum-etl.readthedocs.io/en/latest/)\n",
        "\n",
        "Build the container\n",
        "\n",
        "\n",
        "```\n",
        "docker build -t <hub-user>/<repo-name>:<tag> .\n",
        "```\n",
        "\n",
        "\n",
        "Please replace\n",
        "\n",
        "&lt;hub-user> with your docker hub username, If you don’t have a docker hub account [Follow these instructions to create docker account](https://docs.docker.com/docker-id/), and use the username of the account you created\n",
        "\n",
        "&lt;repo-name> This is the name of the container, you can name it anything you want\n",
        "\n",
        "&lt;tag> This is not required but you can use the latest tag\n",
        "\n",
        "After you have build the container, the next step is to test it locally and then push it docker hub\n",
        "\n",
        "Before pushing you first need to create a repo which you can create by following the instructions here [https://docs.docker.com/docker-hub/repos/](https://docs.docker.com/docker-hub/repos/)\n",
        "\n",
        "Now you can push this repository to the registry designated by its name or tag.\n",
        "\n",
        "\n",
        "```\n",
        " docker push <hub-user>/<repo-name>:<tag>\n",
        "```\n",
        "\n",
        "\n",
        "After the repo image has been pushed to docker hub, we can now use the container for running on bacalhau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjvk7WHzzhBH"
      },
      "source": [
        "\n",
        "# **Running EthereumETL on bacalhau**\n",
        "\n",
        "Structure of the Command\n",
        "\n",
        "`bacalhau docker run ` similar to docker run\n",
        "\n",
        "-v mount the CID to the container this is the \n",
        "\n",
        "CID:/&lt;PATH-TO-WHERE-THE-CID-IS-TO-BE-MOUNTED> `QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz:/files`\n",
        "\n",
        "-- **`ethereumetl extract_csv_column --input transactions.csv --column hash --output ./output/transaction_hashes.csv`** running the command on bacalhau\n",
        "\n",
        "Command:\n",
        "\n",
        "\n",
        "```\n",
        "bacalhau docker run \\\n",
        "-v QmYErPqtdpNTxpKot9pXR5QbhGSyaGdMFxfUwGHm4rzXzH:/transactions.csv \\\n",
        "jsace/ethereum-etl \\\n",
        "-- ethereumetl extract_csv_column --input transactions.csv --column hash --output ./output/transaction_hashes.csv\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24HuygvzTwnT"
      },
      "source": [
        "Insalling bacalhau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1joNKGJT5eN",
        "outputId": "be226f00-179c-4ccf-e741-2f3dc0857b52",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your system is linux_amd64\n",
            "No BACALHAU detected. Installing fresh BACALHAU CLI...\n",
            "Getting the latest BACALHAU CLI...\n",
            "Installing v0.2.5 BACALHAU CLI...\n",
            "Downloading https://github.com/filecoin-project/bacalhau/releases/download/v0.2.5/bacalhau_v0.2.5_linux_amd64.tar.gz ...\n",
            "Downloading sig file https://github.com/filecoin-project/bacalhau/releases/download/v0.2.5/bacalhau_v0.2.5_linux_amd64.tar.gz.signature.sha256 ...\n",
            "Verified OK\n",
            "Extracting tarball ...\n",
            "NOT verifying Bin\n",
            "bacalhau installed into /usr/local/bin successfully.\n",
            "Client Version: v0.2.5\n",
            "Server Version: v0.2.5\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        " curl -sL https://get.bacalhau.org/install.sh | bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htb8W95DU8av",
        "outputId": "c21496c6-347b-4982-c27b-6bd69ee4969a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75ef84c5-1f39-483f-a33f-508c9f7a789a\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "echo $(bacalhau docker run --id-only --wait --wait-timeout-secs 1000 -v QmYErPqtdpNTxpKot9pXR5QbhGSyaGdMFxfUwGHm4rzXzH:/transactions.csv jsace/ethereum-etl -- ethereumetl extract_csv_column --input transactions.csv --column hash --output ./outputs/transaction_hashes.csv) > job_id.txt\n",
        "cat job_id.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UszrZGs4c4i9"
      },
      "source": [
        "\n",
        "Running the commands will output a UUID (like `54506541-4eb9-45f4-a0b1-ea0aecd34b3e`). This is the ID of the job that was created. You can check the status of the job with the following command:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY8x0oyWc6Dq",
        "outputId": "bc092c7e-2cce-4480-e657-eed775346560",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92;100m CREATED  \u001b[0m\u001b[92;100m ID       \u001b[0m\u001b[92;100m JOB                     \u001b[0m\u001b[92;100m STATE     \u001b[0m\u001b[92;100m VERIFIED \u001b[0m\u001b[92;100m PUBLISHED               \u001b[0m\n",
            "\u001b[97;40m 04:45:02 \u001b[0m\u001b[97;40m 75ef84c5 \u001b[0m\u001b[97;40m Docker jsace/ethereu... \u001b[0m\u001b[97;40m Completed \u001b[0m\u001b[97;40m          \u001b[0m\u001b[97;40m /ipfs/QmRcanuDamGtJz... \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "bacalhau list --id-filter $(cat job_id.txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFYpNA32c7t5"
      },
      "source": [
        "\n",
        "Where it says \"`Published `\", that means the job is done, and we can get the results.\n",
        "\n",
        "To find out more information about your job, run the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDnxNH3lVbG1",
        "outputId": "f047196c-f8b8-4c6c-dc1d-184a3651d76f",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JobAPIVersion: \"\"\n",
            "ID: 75ef84c5-1f39-483f-a33f-508c9f7a789a\n",
            "RequesterNodeID: QmYgxZiySj3MRkwLSL4X2MF5F9f2PMhAE3LV49XkfNL1o3\n",
            "ClientID: 14748225207ab2b2535e2f04ecd0ed2b1ac44363d6ef419ba05cca30377d6aca\n",
            "Spec:\n",
            "    Engine: 2\n",
            "    Verifier: 1\n",
            "    Publisher: 4\n",
            "    Docker:\n",
            "        Image: jsace/ethereum-etl\n",
            "        Entrypoint:\n",
            "            - ethereumetl\n",
            "            - extract_csv_column\n",
            "            - --input\n",
            "            - transactions.csv\n",
            "            - --column\n",
            "            - hash\n",
            "            - --output\n",
            "            - ./outputs/transaction_hashes.csv\n",
            "    inputs:\n",
            "        - Engine: 1\n",
            "          Cid: QmYErPqtdpNTxpKot9pXR5QbhGSyaGdMFxfUwGHm4rzXzH\n",
            "          path: /transactions.csv\n",
            "    outputs:\n",
            "        - Engine: 1\n",
            "          Name: outputs\n",
            "          path: /outputs\n",
            "    Sharding:\n",
            "        BatchSize: 1\n",
            "        GlobPatternBasePath: /inputs\n",
            "Deal:\n",
            "    Concurrency: 1\n",
            "CreatedAt: 2022-10-03T04:45:02.775669316Z\n",
            "JobState:\n",
            "    Nodes:\n",
            "        QmYgxZiySj3MRkwLSL4X2MF5F9f2PMhAE3LV49XkfNL1o3:\n",
            "            Shards:\n",
            "                0:\n",
            "                    NodeId: QmYgxZiySj3MRkwLSL4X2MF5F9f2PMhAE3LV49XkfNL1o3\n",
            "                    ShardIndex: 0\n",
            "                    State: 7\n",
            "                    Status: 'Got results proposal of length: 0'\n",
            "                    VerificationProposal: []\n",
            "                    VerificationResult:\n",
            "                        Complete: true\n",
            "                        Result: true\n",
            "                    PublishedResults:\n",
            "                        Engine: 1\n",
            "                        Name: job-75ef84c5-1f39-483f-a33f-508c9f7a789a-shard-0-host-QmYgxZiySj3MRkwLSL4X2MF5F9f2PMhAE3LV49XkfNL1o3\n",
            "                        Cid: QmRcanuDamGtJzYreoP79ButPimGYo6oz2v1T7FPr6GRhP\n",
            "                    RunOutput:\n",
            "                        Stdout: \"\"\n",
            "                        StdoutTruncated: false\n",
            "                        Stderr: \"\"\n",
            "                        StderrTruncated: false\n",
            "                        ExitCode: 0\n",
            "                        RunnerError: \"\"\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "bacalhau describe $(cat job_id.txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I4DHnt0Vzua"
      },
      "source": [
        "Since there is no error we can’t see any error instead we see the state of our job to be complete, that means \n",
        "we can download the results!\n",
        "we create a temporary directory to save our results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fXo1Vv8V84j",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "mkdir results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SuXkeV-WD7j"
      },
      "source": [
        "To Download the results of your job, run \n",
        "\n",
        "---\n",
        "\n",
        "the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha5UFWLYV_5R",
        "outputId": "54d874ff-85f0-4382-9b90-a3d17ed5f2a1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90m04:45:07.642 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mbacalhau/get.go:67\u001b[0m\u001b[36m >\u001b[0m Fetching results of job '75ef84c5-1f39-483f-a33f-508c9f7a789a'...\n",
            "2022/10/03 04:45:08 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 2048 kiB, got: 416 kiB). See https://github.com/lucas-clemente/quic-go/wiki/UDP-Receive-Buffer-Size for details.\n",
            "\u001b[90m04:45:18.137 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mipfs/downloader.go:115\u001b[0m\u001b[36m >\u001b[0m Found 1 result shards, downloading to temporary folder.\n",
            "\u001b[90m04:46:19 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mipfs/downloader.go:195\u001b[0m\u001b[36m >\u001b[0m Combining shard from output volume 'outputs' to final location: '/content/results'\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "bacalhau get  $(cat job_id.txt)  --output-dir results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrZcHon2WOd-"
      },
      "source": [
        "After the download has finished you should \n",
        "see the following contents in results directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5EmAu29WRpa",
        "outputId": "cba3724a-86b9-4ac8-8e12-3279f6ee1d9c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shards\tstderr\tstdout\tvolumes\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "ls results/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLfJC1rAiOHP"
      },
      "source": [
        "VIEWING THE RESULTS CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7DMYf-Jz_cv",
        "outputId": "9c55cec6-51ce-4043-fab5-796b118e6fc8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0x04cbcb236043d8fb7839e07bbc7f5eed692fb2ca55d897f1101eac3e3ad4fab8\n",
            "0xcea6f89720cc1d2f46cc7a935463ae0b99dd5fad9c91bb7357de5421511cee49\n",
            "0x463d53f0ad57677a3b430a007c1c31d15d62c37fab5eee598551697c297c235c\n",
            "0x05287a561f218418892ab053adfb3d919860988b19458c570c5c30f51c146f02\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cat results/volumes/outputs/transaction_hashes.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_DRSYbqKePQ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "bacalhau describe $(cat job_id.txt) --spec > job.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWaY9_LjKiSO",
        "outputId": "ce437b25-7394-48f2-e068-44799b7b2ccf",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JobAPIVersion: \"\"\n",
            "ID: 75ef84c5-1f39-483f-a33f-508c9f7a789a\n",
            "RequesterNodeID: QmYgxZiySj3MRkwLSL4X2MF5F9f2PMhAE3LV49XkfNL1o3\n",
            "ClientID: 14748225207ab2b2535e2f04ecd0ed2b1ac44363d6ef419ba05cca30377d6aca\n",
            "Spec:\n",
            "    Engine: 2\n",
            "    Verifier: 1\n",
            "    Publisher: 4\n",
            "    Docker:\n",
            "        Image: jsace/ethereum-etl\n",
            "        Entrypoint:\n",
            "            - ethereumetl\n",
            "            - extract_csv_column\n",
            "            - --input\n",
            "            - transactions.csv\n",
            "            - --column\n",
            "            - hash\n",
            "            - --output\n",
            "            - ./outputs/transaction_hashes.csv\n",
            "    inputs:\n",
            "        - Engine: 1\n",
            "          Cid: QmYErPqtdpNTxpKot9pXR5QbhGSyaGdMFxfUwGHm4rzXzH\n",
            "          path: /transactions.csv\n",
            "    outputs:\n",
            "        - Engine: 1\n",
            "          Name: outputs\n",
            "          path: /outputs\n",
            "    Sharding:\n",
            "        BatchSize: 1\n",
            "        GlobPatternBasePath: /inputs\n",
            "Deal:\n",
            "    Concurrency: 1\n",
            "CreatedAt: 2022-10-03T04:45:02.782847165Z\n",
            "JobState:\n",
            "    Nodes:\n",
            "        QmYgxZiySj3MRkwLSL4X2MF5F9f2PMhAE3LV49XkfNL1o3:\n",
            "            Shards:\n",
            "                0:\n",
            "                    NodeId: QmYgxZiySj3MRkwLSL4X2MF5F9f2PMhAE3LV49XkfNL1o3\n",
            "                    ShardIndex: 0\n",
            "                    State: 7\n",
            "                    Status: 'Got results proposal of length: 0'\n",
            "                    VerificationProposal: []\n",
            "                    VerificationResult:\n",
            "                        Complete: true\n",
            "                        Result: true\n",
            "                    PublishedResults:\n",
            "                        Engine: 1\n",
            "                        Name: job-75ef84c5-1f39-483f-a33f-508c9f7a789a-shard-0-host-QmYgxZiySj3MRkwLSL4X2MF5F9f2PMhAE3LV49XkfNL1o3\n",
            "                        Cid: QmRcanuDamGtJzYreoP79ButPimGYo6oz2v1T7FPr6GRhP\n",
            "                    RunOutput:\n",
            "                        Stdout: \"\"\n",
            "                        StdoutTruncated: false\n",
            "                        Stderr: \"\"\n",
            "                        StderrTruncated: false\n",
            "                        ExitCode: 0\n",
            "                        RunnerError: \"\"\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cat job.yaml"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
