#!/bin/bash

# This script generates docker-compose.yml with multiple regions, 5 sensors per region,
# and one cosmos uploader per region. This is for TESTING purposes only.
# It uses city information from config/config.yaml.

# Configuration
OUTPUT_FILE="docker-compose.yml"
CONFIG_FILE="config/config.yaml"
SENSORS_PER_CITY=${SENSORS_PER_CITY:-3}    # Can be overridden with environment variable
SENSOR_CONFIG_FILE=${SENSOR_CONFIG_FILE:-"config/sensor-config.yaml"}

# Check if config file exists
if [ ! -f "$CONFIG_FILE" ]; then
  echo "Error: Config file $CONFIG_FILE not found."
  exit 1
fi

# Check if sensor config file exists
if [ ! -f "$SENSOR_CONFIG_FILE" ]; then
  echo "Warning: Sensor configuration file $SENSOR_CONFIG_FILE not found. Using default values."
fi

# Set default uploader values, but allow override via environment variables
UPLOAD_INTERVAL=${UPLOAD_INTERVAL:-30}
ARCHIVE_FORMAT=${ARCHIVE_FORMAT:-"Parquet"}
READINGS_PER_SECOND=${READINGS_PER_SECOND:-1}
ANOMALY_PROBABILITY=${ANOMALY_PROBABILITY:-0.05}

# Extract cities from the YAML file (this assumes the cities section starts with '  - name:')
CITIES=$(grep -A30 "cities:" "$CONFIG_FILE" | grep "name:" | awk -F': ' '{print $2}')
CITY_COUNT=$(echo "$CITIES" | wc -l)

# Start with the header
cat > $OUTPUT_FILE << EOF
# ===================================================================
# TEST DOCKER COMPOSE FILE - MULTI-REGION SETUP
# ===================================================================
# This file is automatically generated for TESTING ONLY.
# It creates $CITY_COUNT regions with $SENSORS_PER_CITY sensors each
# and one dedicated uploader per region.
# ===================================================================

services:
EOF

# Create a counter for naming services uniquely
SENSOR_COUNT=1

# Global array to track used codes to avoid duplicates
declare -a USED_CODES=()

# Function to generate a unique random code
generate_unique_code() {
  local is_unique=false
  local code=""
  
  while [ "$is_unique" = false ]; do
    # Generate a random code
    code=$(cat /dev/urandom | tr -dc 'a-z0-9' | fold -w 4 | head -n 1)
    
    # Check if this code has been used before
    is_unique=true
    for used_code in "${USED_CODES[@]}"; do
      if [ "$used_code" = "$code" ]; then
        is_unique=false
        break
      fi
    done
  done
  
  # Add to the list of used codes
  USED_CODES+=("$code")
  echo "$code"
}

# Process each city and add services
while IFS= read -r CITY; do
  # Get latitude and longitude for this city
  LAT=$(grep -A2 "name: $CITY" "$CONFIG_FILE" | grep "latitude:" | awk -F': ' '{print $2}')
  LONG=$(grep -A3 "name: $CITY" "$CONFIG_FILE" | grep "longitude:" | awk -F': ' '{print $2}')
  
  # City name without spaces for service naming
  CITY_CLEAN=$(echo "$CITY" | tr ' ' '_')
  
  # Create city directory if it doesn't exist
  mkdir -p "./data/$CITY_CLEAN"
  
  # Array to store sensor codes for this city (for depends_on section later)
  declare -a SENSOR_CODES=()
  
  # Add sensors for this city
  for ((i=1; i<=$SENSORS_PER_CITY; i++)); do
    # Generate a unique random 4-character code
    RAND_CODE=$(generate_unique_code)
    SENSOR_CODES+=("$RAND_CODE")
    
    # Create a unique sensor ID with city prefix for better traceability
    CITY_PREFIX=$(echo "$CITY" | tr -cd '[:alnum:]' | cut -c1-3 | tr '[:lower:]' '[:upper:]')
    SENSOR_ID="${CITY_PREFIX}_SENSOR${RAND_CODE}"
    
    # Add the sensor service
    cat >> $OUTPUT_FILE << EOF
  # Sensor $SENSOR_ID in $CITY
  sensor_${CITY_CLEAN}_${RAND_CODE}:
    image: ghcr.io/bacalhau-project/sensor-log-generator:latest
    container_name: sensor_${CITY_CLEAN}_${RAND_CODE}
    environment:
      - READINGS_PER_SECOND=${READINGS_PER_SECOND}
      - ANOMALY_PROBABILITY=${ANOMALY_PROBABILITY}
      - SENSOR_ID=${SENSOR_ID}
      - SENSOR_LOCATION=${CITY}
      - SENSOR_LATITUDE=${LAT}
      - SENSOR_LONGITUDE=${LONG}
    volumes:
      - ./data/${CITY_CLEAN}/${RAND_CODE}:/app/data
      - ./${SENSOR_CONFIG_FILE}:/app/config/sensor-config.yaml
    restart: unless-stopped
    command: ["uv", "run", "-s", "main.py", "--config", "/app/config/sensor-config.yaml"]

EOF
    
    SENSOR_COUNT=$((SENSOR_COUNT+1))
  done
  
  # Add a dedicated uploader for this city
  cat >> $OUTPUT_FILE << EOF
  # Uploader for $CITY
  uploader_${CITY_CLEAN}:
    image: ghcr.io/bacalhau-project/cosmos-uploader:latest
    container_name: uploader_${CITY_CLEAN}
    depends_on:
EOF

  # Add all sensors for this city to the depends_on section
  for CODE in "${SENSOR_CODES[@]}"; do
    echo "      - sensor_${CITY_CLEAN}_${CODE}" >> $OUTPUT_FILE
  done

  # Continue with the rest of the uploader configuration
  cat >> $OUTPUT_FILE << EOF
    environment:
      - DOTNET_ENVIRONMENT=${DOTNET_ENVIRONMENT:-Production}
      - UPLOAD_INTERVAL=${UPLOAD_INTERVAL}
      - ARCHIVE_FORMAT=${ARCHIVE_FORMAT}
      - COSMOS_ENDPOINT=${COSMOS_ENDPOINT}
      - COSMOS_KEY=${COSMOS_KEY}
      - COSMOS_DATABASE=${COSMOS_DATABASE:-SensorData}
      - COSMOS_CONTAINER=${COSMOS_CONTAINER:-SensorReadings}
      - REGION=${CITY}
    volumes:
      - ./config:/app/config
      - ./data/${CITY_CLEAN}:/app/data
      - ./archive/${CITY_CLEAN}:/app/archive
    command: ["--config", "/app/config/config.yaml", "--sqlite", "/app/data", "--continuous", "--interval", "${UPLOAD_INTERVAL}", "--archive-path", "/app/archive"]
    restart: unless-stopped

EOF

done <<< "$CITIES"

# Add volumes section for persistent storage
cat >> $OUTPUT_FILE << EOF
volumes:
  sensor_data:
    driver: local
  archive_data:
    driver: local
EOF

echo "Generated $OUTPUT_FILE with $((SENSORS_PER_CITY * CITY_COUNT)) sensor replicas across $CITY_COUNT cities."
echo "Configuration uses Docker Compose with one dedicated uploader per city."
echo "WARNING: This is a test-only configuration and not intended for production use."
echo "Sensors per city: $SENSORS_PER_CITY, Number of cities: $CITY_COUNT"