{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "source": [
        "---\n",
        "sidebar_label: 'Simple Parallel Workloads'\n",
        "sidebar_position: 2\n",
        "description: \"Parallel Video Resizing via File Sharding\"\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "source": [
        "# Parallel Video Resizing via File Sharding\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bacalhau-project/examples/blob/main/data-engineering/simple-parallel-workloads/index.ipynb)\n",
        "[![Open In Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/bacalhau-project/examples/HEAD?labpath=data-engineering%2Fsimple-parallel-workloads%2Findex.ipynb)\n",
        "\n",
        "Many data engineering workloads consist of embarrassingly parallel workloads where you want to run a simple execution on a large number of files. In this notebook, we will use the [Sharding](https://docs.bacalhau.org/getting-started/parallel-workloads) functionality in Bacalhau to run a simple video filter on a large number of video files.\n",
        "\n",
        "> Although you would normally you would use your own container and script to make your workloads reproducible, in this example we will use a pre-built container and CLI arguments to allow you to make changes. You can find the container [on docker hub](https://hub.docker.com/r/linuxserver/ffmpeg)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "source": [
        "## Prerequistes\n",
        "\n",
        "Make sure you have the latest `bacalhau` client installed by following the [getting started instructions](../../../getting-started/installation) or using the installation command below (which installs Bacalhau local to the notebook)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your system is linux_amd64\n",
            "No BACALHAU detected. Installing fresh BACALHAU CLI...\n",
            "Getting the latest BACALHAU CLI...\n",
            "Installing v0.3.15 BACALHAU CLI...\n",
            "Downloading https://github.com/filecoin-project/bacalhau/releases/download/v0.3.15/bacalhau_v0.3.15_linux_amd64.tar.gz ...\n",
            "Downloading sig file https://github.com/filecoin-project/bacalhau/releases/download/v0.3.15/bacalhau_v0.3.15_linux_amd64.tar.gz.signature.sha256 ...\n",
            "Verified OK\n",
            "Extracting tarball ...\n",
            "NOT verifying Bin\n",
            "bacalhau installed into . successfully.\n",
            "Client Version: v0.3.15\n",
            "Server Version: v0.3.15\n",
            "env: PATH=./:/home/gitpod/.pyenv/versions/3.8.13/bin:/home/gitpod/.pyenv/libexec:/home/gitpod/.pyenv/plugins/python-build/bin:/home/gitpod/.pyenv/plugins/pyenv-virtualenv/bin:/home/gitpod/.pyenv/plugins/pyenv-update/bin:/home/gitpod/.pyenv/plugins/pyenv-installer/bin:/home/gitpod/.pyenv/plugins/pyenv-doctor/bin:/home/gitpod/.pyenv/shims:/ide/bin/remote-cli:/home/gitpod/.nix-profile/bin:/home/gitpod/.local/bin:/home/gitpod/.sdkman/candidates/maven/current/bin:/home/gitpod/.sdkman/candidates/java/current/bin:/home/gitpod/.sdkman/candidates/gradle/current/bin:/workspace/.cargo/bin:/home/gitpod/.rvm/gems/ruby-3.1.2/bin:/home/gitpod/.rvm/gems/ruby-3.1.2@global/bin:/home/gitpod/.rvm/rubies/ruby-3.1.2/bin:/home/gitpod/.pyenv/plugins/pyenv-virtualenv/shims:/home/gitpod/.pyenv/shims:/workspace/go/bin:/home/gitpod/.nix-profile/bin:/ide/bin/remote-cli:/home/gitpod/go/bin:/home/gitpod/go-packages/bin:/home/gitpod/.nvm/versions/node/v16.18.1/bin:/home/gitpod/.yarn/bin:/home/gitpod/.pnpm:/home/gitpod/.pyenv/bin:/workspace/.rvm/bin:/home/gitpod/.cargo/bin:/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin/:/home/gitpod/.local/bin:/usr/games:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/gitpod/.nvm/versions/node/v16.18.1/bin:/home/gitpod/.rvm/bin\n"
          ]
        }
      ],
      "source": [
        "!command -v bacalhau >/dev/null 2>&1 || (export BACALHAU_INSTALL_DIR=.; curl -sL https://get.bacalhau.org/install.sh | bash)\n",
        "path=!echo $PATH\n",
        "%env PATH=./:{path[0]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Client Version: v0.3.15\n",
            "Server Version: v0.3.15\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "bacalhau version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "source": [
        "## Submit the workload\n",
        "\n",
        "To submit a workload to Bacalhau you can use the `bacalhau docker run` command. This allows you to pass input data volume with a `-v CID:path` argument just like Docker, except the left-hand side of the argument is a [content identifier (CID)](https://github.com/multiformats/cid). This results in Bacalhau mounting a *data volume* inside the container. By default, Bacalhau mounts the input volume at the path `/inputs` inside the container.\n",
        "\n",
        "Bacalhau also mounts a data volume to store output data. By default `bacalhau docker run` creates an output data volume mounted at `/outputs`. This is a convenient location to store the results of your job. See below for an example.\n",
        "\n",
        "And to shard across files in the input directory, we need to pass three (optional) arguments to the command:\n",
        "\n",
        "* `sharding-base-path` - the path to the directory you want to shard over\n",
        "* `sharding-glob-pattern` - the pattern to match files in the directory\n",
        "* `sharding-batch-size` - the number of files to pass into each job\n",
        "\n",
        "### A Simple Video Resize Example\n",
        "\n",
        "In this example, you will create 72px wide video thumbnails for all the videos in the `inputs` directory. The `outputs` directory will contain the thumbnails for each video. We will shard by 1 video per job, and use the `linuxserver/ffmpeg` container to resize the videos.\n",
        "\n",
        "Note that [Bacalhau overwrites the default entrypoint](https://github.com/filecoin-project/bacalhau/blob/v0.2.3/cmd/bacalhau/docker_run.go#L64) so we must run the full command after the `--` argument. In this line you will list all of the mp4 files in the `/inputs` directory and execute `ffmpeg` against each instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "%%bash --out job_id\n",
        "bacalhau docker run \\\n",
        "  --wait \\\n",
        "  --wait-timeout-secs 100 \\\n",
        "  --id-only \\\n",
        "  --sharding-base-path \"/inputs\" \\\n",
        "  --sharding-glob-pattern \"*.mp4\" \\\n",
        "  --sharding-batch-size 1 \\\n",
        "  -v Qmd9CBYpdgCLuCKRtKRRggu24H72ZUrGax5A9EYvrbC72j:/inputs \\\n",
        "  linuxserver/ffmpeg -- \\\n",
        "  bash -c 'find /inputs -iname \"*.mp4\" -printf \"%f\\n\" | xargs -I{} ffmpeg -y -i /inputs/{} -vf \"scale=-1:72,setsar=1:1\" /outputs/scaled_{}'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: JOB_ID=393bb955-a8c2-45b8-b32b-93a06fa73bd5\n"
          ]
        }
      ],
      "source": [
        "%env JOB_ID={job_id}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "source": [
        "## Get Results\n",
        "\n",
        "Now let's download and display the result from the results directory. We can use the `bacalhau results` command to download the results from the output data volume. The `--output-dir` argument specifies the directory to download the results to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching results of job '393bb955-a8c2-45b8-b32b-93a06fa73bd5'...\n",
            "Results for job '393bb955-a8c2-45b8-b32b-93a06fa73bd5' have been written to...\n",
            "./results\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "mkdir -p ./results # Temporary directory to store the results\n",
        "bacalhau get --output-dir ./results ${JOB_ID} # Download the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'results/volumes/outputs/*': No such file or directory\n",
            "mv: cannot stat '* *': No such file or directory\n"
          ]
        },
        {
          "ename": "CalledProcessError",
          "evalue": "Command 'b'# Copy the files to the local directory, to allow the documentation scripts to copy them to the right place\\ncp results/volumes/outputs/* ./ && rm -rf results/volumes/outputs/*\\n# Remove any spaces from the filenames\\nfor f in *\\\\ *; do mv \"$f\" \"${f// /_}\"; done\\n'' returned non-zero exit status 1.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_cell_magic(\u001b[39m'\u001b[39m\u001b[39mbash\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m# Copy the files to the local directory, to allow the documentation scripts to copy them to the right place\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mcp results/volumes/outputs/* ./ && rm -rf results/volumes/outputs/*\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m# Remove any spaces from the filenames\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mfor f in *\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m *; do mv \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m$f\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m$\u001b[39m\u001b[39m{\u001b[39m\u001b[39mf// /_}\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m; done\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2362\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2360\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2361\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2362\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2363\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[39m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshebang(line, cell)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mraise_error \u001b[39mand\u001b[39;00m p\u001b[39m.\u001b[39mreturncode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[39m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[39m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[39m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mreturncode \u001b[39mor\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'# Copy the files to the local directory, to allow the documentation scripts to copy them to the right place\\ncp results/volumes/outputs/* ./ && rm -rf results/volumes/outputs/*\\n# Remove any spaces from the filenames\\nfor f in *\\\\ *; do mv \"$f\" \"${f// /_}\"; done\\n'' returned non-zero exit status 1."
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# Copy the files to the local directory, to allow the documentation scripts to copy them to the right place\n",
        "cp results/volumes/outputs/* ./ && rm -rf results/volumes/outputs/*\n",
        "# Remove any spaces from the filenames\n",
        "for f in *\\ *; do mv \"$f\" \"${f// /_}\"; done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video src=\"scaled_Bird_flying_over_the_lake.mp4\" controls  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<video src=\"scaled_Calm_waves_on_a_rocky_sea_gulf.mp4\" controls  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<video src=\"scaled_Prominent_Late_Gothic_styled_architecture.mp4\" controls  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import glob\n",
        "from IPython.display import Video, display\n",
        "for file in glob.glob('*.mp4'):\n",
        "    display(Video(filename=file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "source": [
        "<!-- This is for the benefit of the documentation -->\n",
        "<video src={require('./scaled_Bird_flying_over_the_lake.mp4').default} controls  >\n",
        "Your browser does not support the <code>video</code> element.\n",
        "</video>\n",
        "<video src={require('./scaled_Calm_waves_on_a_rocky_sea_gulf.mp4').default} controls  >\n",
        "Your browser does not support the <code>video</code> element.\n",
        "</video>\n",
        "<video src={require('./scaled_Prominent_Late_Gothic_styled_architecture.mp4').default} controls  >\n",
        "Your browser does not support the <code>video</code> element.\n",
        "</video>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
