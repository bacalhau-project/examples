name: bacalhau-network

x-common-env-variables: &common-env-variables
  BACALHAU_DISABLEANALYTICS: true
  LOG_LEVEL: info
  MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
  MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
  AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minioadmin}
  AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}

# Common logging configuration to disable logs
x-logging-driver: &logging-driver
  logging:
    driver: "none"

x-sensor-template: &sensor-template
  image: ghcr.io/bacalhau-project/bacalhau:v1.7.0-dind
  platform: linux/amd64
  entrypoint: "/usr/local/bin/entrypoint.sh sh -c"
  command: >
    "env >> /etc/environment &&
    mkdir -p /mnt/data &&
    bacalhau serve -c /etc/bacalhau/config.yaml"
  privileged: true
  restart: on-failure
  volumes:
    - ./bacalhau-config/compute.yaml:/etc/bacalhau/config.yaml
    - ./docker-config/daemon.json:/etc/docker/daemon.json
  depends_on:
    orchestrator:
      condition: service_healthy
    storage:
      condition: service_healthy
    ferretdb:
      condition: service_started
  dns:
    - 1.1.1.1
  networks:
    - bacalhau-network

services:
  orchestrator:
    image: ghcr.io/bacalhau-project/bacalhau:v1.7.0
    platform: linux/amd64
    hostname: orchestrator
    container_name: ferret-demo-orchestrator
    command: serve -c /etc/bacalhau/config.yaml --name orchestrator
    environment: *common-env-variables
    ports:
      - "8438:8438"
    volumes:
      - ./bacalhau-config/orchestrator.yaml:/etc/bacalhau/config.yaml
      - ./docker-config/daemon.json:/etc/docker/daemon.json
    healthcheck:
      test: ["CMD", "bacalhau", "agent", "alive"]
      interval: 30s
      timeout: 20s
      retries: 10
      start_period: 15s
    networks:
      - bacalhau-network

  nodes:
    image: ghcr.io/bacalhau-project/bacalhau:latest-dind
    privileged: true
    command: serve -c /etc/bacalhau/config.yaml
    volumes:
      - ./network-config/compute.yaml:/etc/bacalhau/config.yaml
      - ./docker-config/daemon.json:/etc/docker/daemon.json
    environment:
      <<: *common-env-variables
    depends_on:
      orchestrator:
        condition: service_healthy
    networks:
      - bacalhau-network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    dns:
      - 1.1.1.1
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
  #    <<: *logging-driver

  client:
    image: ghcr.io/bacalhau-project/bacalhau:v1.7.0
    platform: linux/amd64
    container_name: ferret-demo-client
    entrypoint: /bin/sh
    stdin_open: true
    tty: true
    stop_signal: SIGTERM
    stop_grace_period: 3s
    environment:
      <<: *common-env-variables
      BACALHAU_API_HOST: orchestrator
    volumes:
      - ./scripts:/scripts
      - ./jobs:/jobs
      - ./1_run_generate_sensor_logs_job.sh:/1_run_generate_sensor_logs_job.sh
      - ./2_run_sync_sensor_logs_job.sh:/2_run_sync_sensor_logs_job.sh
      - ./3_replace_sync_sensor_logs_script.sh:/3_replace_sync_sensor_logs_script.sh
      - ./4_run_cleanup_whole_mongodb_job.sh:/4_run_cleanup_whole_mongodb_job.sh
    depends_on:
      - orchestrator
    networks:
      - bacalhau-network

  registry-proxy:
    image: registry:2
    ports:
      - "5000:5000"
    volumes:
      - registry-data:/var/lib/registry
    networks:
      - bacalhau-network

  minio:
    image: quay.io/minio/minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000" # S3 API
      - "9001:9001" # Web console
    volumes:
      - minio-data:/data
    networks:
      - bacalhau-network

  spark-master:
    image: bitnami/spark:3.5.1
    depends_on: [minio]
    environment:
      - SPARK_MODE=master
      - SPARK_DAEMON_MEMORY=1G
      - SPARK_EXTRA_CLASSPATH=/opt/delta/jars/*
    volumes:
      - ../../tools/local-lakehouse/spark/conf:/opt/bitnami/spark/conf:ro
      - ../../tools/local-lakehouse/spark/jars:/opt/delta/jars:ro
    networks:
      - bacalhau-network

  spark-worker:
    image: bitnami/spark:3.5.1
    depends_on: [spark-master]
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_EXTRA_CLASSPATH=/opt/delta/jars/*
    volumes:
      - ../../tools/local-lakehouse/spark/jars:/opt/delta/jars:ro
    networks:
      - bacalhau-network

  delta-lake:
    image: deltaio/delta-docker:${DELTA_IMAGE_TAG:-latest}   # use *_arm64 tag on Apple-Silicon
    container_name: delta-lake
    entrypoint: ["/startup.sh"]
    ports:
      - "8888:8888"    # JupyterLab
      - "4040:4040"    # Spark UI (first app)
    volumes:
      - ./notebooks:/opt/spark/work-dir/notebooks            # keep existing notebooks
      - ./data/delta:/tmp                                    # persistent Delta tables
    environment:
      <<: *common-env-variables
      # Make MinIO reachable from Spark-in-container
      AWS_S3_ENDPOINT: http://minio:9000
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minioadmin}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
    depends_on:
      minio:
        condition: service_started
    networks:
      - bacalhau-network

networks:
  bacalhau-network:
    ipam:
      config:
        - subnet: 172.28.0.0/16
    driver_opts:
      com.docker.network.driver.mtu: 1450

volumes:
  registry-data:
  minio-data: {}
