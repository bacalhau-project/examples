#!/usr/bin/env uv
# /// script
# requires-python = ">=3.9"
# dependencies = []
# ///

import os
import base64
import sys
from pathlib import Path
import stat

def generate_additional_commands(credentials_dir="credentials", output_file="additional-commands.sh"):
    """Generate an additional commands script with embedded credentials for AWS spot deployer."""
    
    if not os.path.exists(credentials_dir):
        print(f"Error: Credentials directory '{credentials_dir}' not found")
        sys.exit(1)
    
    # Collect all files from credentials directory
    embedded_files = {}
    
    for root, dirs, files in os.walk(credentials_dir):
        for file in files:
            file_path = os.path.join(root, file)
            rel_path = os.path.relpath(file_path, credentials_dir)
            
            with open(file_path, 'rb') as f:
                content = f.read()
                encoded = base64.b64encode(content).decode('utf-8')
                embedded_files[rel_path] = encoded
    
    if not embedded_files:
        print(f"Error: No files found in '{credentials_dir}' directory")
        sys.exit(1)
    
    # Generate the additional commands script
    script_content = '''#!/bin/bash
# Additional commands script with embedded credentials for Databricks uploader
# Generated by generate-additional-commands.py
# This script is executed by deploy_services.py after the main deployment

set -e

echo "[$(date)] Starting additional commands for Databricks credential setup"

# Create credentials directory in bacalhau_data
CREDS_DIR="/bacalhau_data/credentials"
echo "[$(date)] Creating credentials directory at $CREDS_DIR"
sudo mkdir -p "$CREDS_DIR"
sudo chown ubuntu:ubuntu "$CREDS_DIR"

# Decode and write embedded credentials
'''
    
    # Add each embedded file
    for rel_path, encoded_content in embedded_files.items():
        # Split encoded content into chunks for readability
        chunks = [encoded_content[i:i+76] for i in range(0, len(encoded_content), 76)]
        
        script_content += f'''
# Write {rel_path}
echo "[$(date)] Writing credential file: {rel_path}"
mkdir -p "$CREDS_DIR/$(dirname "{rel_path}")" 2>/dev/null || true
cat > "$CREDS_DIR/{rel_path}.b64" << 'EOF_CRED_{rel_path.replace("/", "_").replace("-", "_").replace(".", "_")}'
'''
        
        # Write the base64 encoded content
        for chunk in chunks:
            script_content += chunk + '\n'
        
        script_content += f'''EOF_CRED_{rel_path.replace("/", "_").replace("-", "_").replace(".", "_")}

# Decode the file
base64 -d "$CREDS_DIR/{rel_path}.b64" > "$CREDS_DIR/{rel_path}"
rm -f "$CREDS_DIR/{rel_path}.b64"
chmod 600 "$CREDS_DIR/{rel_path}"
'''
    
    # Add environment variable exports and final setup
    script_content += '''
echo "[$(date)] Setting permissions on credentials"
sudo chown -R ubuntu:ubuntu "$CREDS_DIR"
chmod -R 600 "$CREDS_DIR"

# Create a script to export credentials for the Databricks uploader
cat > /opt/databricks-credentials.sh << 'EOF'
#!/bin/bash
# Source this file to load Databricks credentials

export DATABRICKS_CREDS_DIR="/bacalhau_data/credentials"

# Look for specific credential files and export environment variables
if [ -f "$DATABRICKS_CREDS_DIR/databricks-token" ]; then
    export DATABRICKS_TOKEN=$(cat "$DATABRICKS_CREDS_DIR/databricks-token")
fi

# Source AWS credentials if they exist
if [ -f "$DATABRICKS_CREDS_DIR/expanso-s3-env.sh" ]; then
    source "$DATABRICKS_CREDS_DIR/expanso-s3-env.sh"
elif [ -f "$DATABRICKS_CREDS_DIR/expanso-s3-credentials" ]; then
    source "$DATABRICKS_CREDS_DIR/expanso-s3-credentials"
fi

# Export paths to config files
if [ -f "$DATABRICKS_CREDS_DIR/databricks-storage-config.yaml" ]; then
    export DATABRICKS_STORAGE_CONFIG="$DATABRICKS_CREDS_DIR/databricks-storage-config.yaml"
fi

if [ -f "$DATABRICKS_CREDS_DIR/expanso-databricks-s3.yaml" ]; then
    export DATABRICKS_S3_CONFIG="$DATABRICKS_CREDS_DIR/expanso-databricks-s3.yaml"
fi

echo "[$(date)] Databricks credentials loaded"
EOF

chmod +x /opt/databricks-credentials.sh
sudo chown ubuntu:ubuntu /opt/databricks-credentials.sh

# Create systemd environment file for services
echo "[$(date)] Creating systemd environment file"
cat > /tmp/databricks-env << 'EOF'
# Databricks environment variables for systemd services
DATABRICKS_CREDS_DIR=/bacalhau_data/credentials
EOF

# Add specific environment variables if files exist
if [ -f "$CREDS_DIR/databricks-token" ]; then
    echo "DATABRICKS_TOKEN=$(cat $CREDS_DIR/databricks-token)" >> /tmp/databricks-env
fi

# Move to systemd location
sudo mv /tmp/databricks-env /etc/databricks-env
sudo chmod 644 /etc/databricks-env

echo "[$(date)] Credentials setup completed successfully"
echo "[$(date)] Credentials location: $CREDS_DIR"
echo "[$(date)] To use credentials: source /opt/databricks-credentials.sh"

# Run the Databricks uploader setup if it exists
if [ -f /opt/uploaded_files/scripts/setup-databricks-uploader.sh ]; then
    echo "[$(date)] Running Databricks uploader setup"
    source /opt/databricks-credentials.sh
    /opt/uploaded_files/scripts/setup-databricks-uploader.sh
fi

echo "[$(date)] Additional commands for Databricks completed"
'''
    
    # Write the generated script
    with open(output_file, 'w') as f:
        f.write(script_content)
    
    # Make the script executable
    st = os.stat(output_file)
    os.chmod(output_file, st.st_mode | stat.S_IEXEC)
    
    print(f"Generated additional commands script: {output_file}")
    print(f"Embedded {len(embedded_files)} credential files:")
    for rel_path in embedded_files:
        print(f"  - {rel_path}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Generate additional commands script with embedded credentials")
    parser.add_argument("--credentials-dir", default="credentials", 
                        help="Directory containing credential files (default: credentials)")
    parser.add_argument("--output", default="additional-commands.sh",
                        help="Output filename for the generated script (default: additional-commands.sh)")
    
    args = parser.parse_args()
    
    generate_additional_commands(args.credentials_dir, args.output)