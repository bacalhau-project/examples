{"cells":[{"cell_type":"markdown","metadata":{"id":"7XAPmZxCt6rv"},"source":["# Running BIDS Apps on bacalhau\n","\n","\n","# Introduction\n","\n","What is a BIDS App? ([source](https://bids-apps.neuroimaging.io/about/))\n","\n","A BIDS App is a container image capturing a neuroimaging pipeline that takes a BIDS formatted dataset as input. BIDS (Brain Imaging Data Structure) is an emerging standard for organizing and describing neuroimaging datasets. Each BIDS App has the same core set of command line arguments, making them easy to run and integrate into automated platforms. BIDS Apps are constructed in a way that does not depend on any software outside of the image other than the container engine."]},{"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bacalhau-project/examples/blob/main/miscellaneous/BIDS/index.ipynb)\n","[![Open In Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/bacalhau-project/examples/HEAD?labpath=miscellaneous/BIDS/index.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"t3Hfa9Q0uA5I"},"source":["\n","## **Downloading datasets**\n","\n","You can find the bids datasets in this google drive folder [archives](https://drive.google.com/drive/folders/0B2JWN60ZLkgkMGlUY3B4MXZIZW8?resourcekey=0-EYVSOlRbxeFKO8NpjWWM3w) \n","\n","download the relevant data, [ds005.tar](https://drive.google.com/drive/folders/0B2JWN60ZLkgkMGlUY3B4MXZIZW8), and untar it in a directory. `ds005` will be our input directory in the following example.\n","\n","\n","```\n","data\n","└── ds005\n","```\n","\n","\n","\n","\n","### **Uploading the datasets to IPFS**\n","\n","Upload the directory to IPFS using IPFS CLI ([Installation Instructions](https://docs.ipfs.tech/install/command-line/#official-distributions))\n","\n","\n","```\n","$ ipfs add -r data\n","added QmdsFcNbja8vbeNEj6HGfbvJmuu3cXUmgV4CR3HQqNqsNK data/ds005/CHANGES\n","                                    .\n","                                    .\n","                                    .\n","added QmdnMxSSvD8QYR6F4S7wkgQsW16bR6U7zyDTbiEm72RPpB data/ds005\n","added QmaNyzSpJCt1gMCQLd3QugihY6HzdYmA8QMEa45LDBbVPz data\n"," 1.77 GiB / 1.77 GiB [=========================================================================================] 100.00%\n","```\n","\n","\n","Copy the CID in the end which is `QmaNyzSpJCt1gMCQLd3QugihY6HzdYmA8QMEa45LDBbVPz`\n","\n","Upload the directory to IPFS using [Pinata](https://app.pinata.cloud/) (Recommended)\n","\n","Click on the upload folder button and select the bids datasets folder that you want to upload\n","\n","![](https://i.imgur.com/btnHw3N.png)\n","\n","\n","After the Upload has finished copy the CID (highlighted part)\n","\n","![](https://i.imgur.com/rETHXXz.png)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1979,"status":"ok","timestamp":1664565013333,"user":{"displayName":"Vedant Padwal","userId":"05534807475078682627"},"user_tz":-330},"id":"W2nEruwiqbb9","outputId":"9088e807-2b36-4105-c5f1-263da0b11399","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-09-30 19:10:07--  https://dist.ipfs.io/go-ipfs/v0.4.2/go-ipfs_v0.4.2_linux-amd64.tar.gz\n","Resolving dist.ipfs.io (dist.ipfs.io)... 209.94.78.1, 2602:fea2:3::1\n","Connecting to dist.ipfs.io (dist.ipfs.io)|209.94.78.1|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7642422 (7.3M) [application/gzip]\n","Saving to: ‘go-ipfs_v0.4.2_linux-amd64.tar.gz.1’\n","\n","go-ipfs_v0.4.2_linu 100%[===================>]   7.29M  40.8MB/s    in 0.2s    \n","\n","2022-09-30 19:10:07 (40.8 MB/s) - ‘go-ipfs_v0.4.2_linux-amd64.tar.gz.1’ saved [7642422/7642422]\n","\n","go-ipfs/build-log\n","go-ipfs/install.sh\n","go-ipfs/ipfs\n","go-ipfs/LICENSE\n","go-ipfs/README.md\n","initializing ipfs node at /root/.ipfs\n","Error: ipfs configuration file already exists!\n","Reinitializing would overwrite your keys.\n","\n","Hello and Welcome to IPFS!\n","\n","██╗██████╗ ███████╗███████╗\n","██║██╔══██╗██╔════╝██╔════╝\n","██║██████╔╝█████╗  ███████╗\n","██║██╔═══╝ ██╔══╝  ╚════██║\n","██║██║     ██║     ███████║\n","╚═╝╚═╝     ╚═╝     ╚══════╝\n","\n","If you're seeing this, you have successfully installed\n","IPFS and are now interfacing with the ipfs merkledag!\n","\n"," -------------------------------------------------------\n","| Warning:                                              |\n","|   This is alpha software. Use at your own discretion! |\n","|   Much is missing or lacking polish. There are bugs.  |\n","|   Not yet secure. Read the security notes for more.   |\n"," -------------------------------------------------------\n","\n","Check out some of the other files in this directory:\n","\n","  ./about\n","  ./help\n","  ./quick-start     <-- usage examples\n","  ./readme          <-- this file\n","  ./security-notes\n","nohup: redirecting stderr to stdout\n"]}],"source":["!mkdir data\n","!wget https://dist.ipfs.io/go-ipfs/v0.4.2/go-ipfs_v0.4.2_linux-amd64.tar.gz\n","!tar xvfz go-ipfs_v0.4.2_linux-amd64.tar.gz\n","!mv go-ipfs/ipfs /usr/local/bin/ipfs\n","!cd data\n","!ipfs init\n","!ipfs cat /ipfs/QmYwAPJzv5CZsnA625s3Xf2nemtYgPpHdWEz79ojWnPbdG/readme\n","!ipfs config Addresses.Gateway /ip4/127.0.0.1/tcp/8082\n","!nohup ipfs daemon > startup.log &"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":196735,"status":"ok","timestamp":1664565223685,"user":{"displayName":"Vedant Padwal","userId":"05534807475078682627"},"user_tz":-330},"id":"pPlu98qox9gy","outputId":"be272e44-284b-4e99-c02b-6dca15fab5bb","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Error: request canceled\n"]}],"source":["!cd data\n","!ipfs get QmdnMxSSvD8QYR6F4S7wkgQsW16bR6U7zyDTbiEm72RPpB"]},{"cell_type":"markdown","metadata":{"id":"TrmHfJdP0h4c"},"source":["\n","**Running the command on bacalhau**\n","\n","The command can be broken down into 4 pieces\n","\n","`bacalhau docker run` using the docker backend\n","\n","`-v QmaNyzSpJCt1gMCQLd3QugihY6HzdYmA8QMEa45LDBbVPz:/data` here we mount the CID of the dataset we uploaded to IPFS and mount it to a folder called data on the container\n","\n","`nipreps/mriqc:latest` the name and the tag of the docker image we are using\n","\n","\n","```\n","mriqc ../data/ds005 ../outputs participant --participant_label 01 02 03\n","```\n","\n","\n","This is the command that we run where we specify path to the `../data/ds005` input dataset\n","\n","`../outputs` path where we want to save our outputs,\n","\n","`participant --participant_label 01 02 03` Run the participant level in subjects 001 002 003\n","\n","\n","```\n","bacalhau docker run \\\n","-v QmaNyzSpJCt1gMCQLd3QugihY6HzdYmA8QMEa45LDBbVPz:/data \\\n","nipreps/mriqc:latest \\\n","-- mriqc ../data/ds005 ../outputs participant --participant_label 01 02 03\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"24HuygvzTwnT"},"source":["Insalling bacalhau"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3712,"status":"ok","timestamp":1663499759698,"user":{"displayName":"Vedant Padwal","userId":"05534807475078682627"},"user_tz":-330},"id":"W1joNKGJT5eN","outputId":"a703088d-4c44-426a-a24d-6e928159898b","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Your system is linux_amd64\n","No BACALHAU detected. Installing fresh BACALHAU CLI...\n","Getting the latest BACALHAU CLI...\n","Installing v0.2.3 BACALHAU CLI...\n","Downloading https://github.com/filecoin-project/bacalhau/releases/download/v0.2.3/bacalhau_v0.2.3_linux_amd64.tar.gz ...\n","Downloading sig file https://github.com/filecoin-project/bacalhau/releases/download/v0.2.3/bacalhau_v0.2.3_linux_amd64.tar.gz.signature.sha256 ...\n","Verified OK\n","Extracting tarball ...\n","NOT verifying Bin\n","bacalhau installed into /usr/local/bin successfully.\n","Client Version: v0.2.3\n","Server Version: v0.2.3\n"]}],"source":["!curl -sL https://get.bacalhau.org/install.sh | bash"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Htb8W95DU8av","vscode":{"languageId":"python"}},"outputs":[],"source":["%%bash\n","echo $(bacalhau docker run --id-only --wait --wait-timeout-secs 1000 -v QmaNyzSpJCt1gMCQLd3QugihY6HzdYmA8QMEa45LDBbVPz:/data nipreps/mriqc:latest -- mriqc ../data/ds005 ../outputs participant --participant_label 01 02 03) > job_id.txt\n","cat job_id.txt"]},{"cell_type":"markdown","metadata":{"id":"UszrZGs4c4i9"},"source":["\n","Running the commands will output a UUID (like `54506541-4eb9-45f4-a0b1-ea0aecd34b3e`). This is the ID of the job that was created. You can check the status of the job with the following command:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jY8x0oyWc6Dq","vscode":{"languageId":"python"}},"outputs":[],"source":["%%bash\n","bacalhau list --id-filter $(cat job_id.txt)"]},{"cell_type":"markdown","metadata":{"id":"kFYpNA32c7t5"},"source":["\n","Where it says \"`Published `\", that means the job is done, and we can get the results.\n","\n","To find out more information about your job, run the following command:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FDnxNH3lVbG1","vscode":{"languageId":"python"}},"outputs":[],"source":["%%bash\n","bacalhau describe $(cat job_id.txt)"]},{"cell_type":"markdown","metadata":{"id":"2I4DHnt0Vzua"},"source":["Since there is no error we can’t see any error instead we see the state of our job to be complete, that means \n","we can download the results!\n","we create a temporary directory to save our results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9fXo1Vv8V84j","vscode":{"languageId":"python"}},"outputs":[],"source":["%%bash\n","mkdir results"]},{"cell_type":"markdown","metadata":{"id":"6SuXkeV-WD7j"},"source":["To Download the results of your job, run \n","\n","---\n","\n","the following command:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15175,"status":"ok","timestamp":1663503591277,"user":{"displayName":"Vedant Padwal","userId":"05534807475078682627"},"user_tz":-330},"id":"Ha5UFWLYV_5R","outputId":"c8220180-3afa-4bfc-9e5f-a6ea5919c853","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[90m12:19:36.609 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mbacalhau/get.go:67\u001b[0m\u001b[36m >\u001b[0m Fetching results of job 'ab354ccc-f02e-4262-ad0b-f33ec78803cc'...\n","2022/09/18 12:19:37 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 2048 kiB, got: 416 kiB). See https://github.com/lucas-clemente/quic-go/wiki/UDP-Receive-Buffer-Size for details.\n","\u001b[90m12:19:47.364 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mipfs/downloader.go:115\u001b[0m\u001b[36m >\u001b[0m Found 1 result shards, downloading to temporary folder.\n","\u001b[90m12:19:51.091 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mipfs/downloader.go:195\u001b[0m\u001b[36m >\u001b[0m Combining shard from output volume 'outputs' to final location: '/content/results'\n"]}],"source":["%%bash\n","bacalhau get  $(cat job_id.txt)  --output-dir results"]},{"cell_type":"markdown","metadata":{"id":"nrZcHon2WOd-"},"source":["After the download has finished you should \n","see the following contents in results directory"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":372,"status":"ok","timestamp":1663503614756,"user":{"displayName":"Vedant Padwal","userId":"05534807475078682627"},"user_tz":-330},"id":"C5EmAu29WRpa","outputId":"a8c56ce7-e4f6-4664-a669-734b4f26f31a","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["shards\tstderr\tstdout\tvolumes\n"]}],"source":["%%bash\n","ls results/"]},{"cell_type":"markdown","metadata":{"id":"qg5MtLC21maJ"},"source":["\n","The structure of the files and directories will look like this:\n","\n","\n","```\n",".\n","├── shards\n","│   └── job-8e89eb2f-1ae7-4b92-ba72-8abfade02a23-shard-0-host-QmYgxZiySj3MRkwLSL4X2MF5F9f2PMhAE3LV49XkfNL1o3\n","│       ├── exitCode\n","│       ├── stderr\n","│       └── stdout\n","├── stderr\n","├── stdout\n","└── volumes\n","    └── outputs\n","        ├── dataset_description.json\n","        ├── sub-01_T1w.html\n","        ├── sub-01_T1w.json\n","        ├── sub-01_task-mixedgamblestask_run-01_bold.html\n","        ├── sub-01_task-mixedgamblestask_run-01_bold.json\n","        ├── sub-01_task-mixedgamblestask_run-02_bold.html\n","        ├── sub-01_task-mixedgamblestask_run-02_bold.json\n","        ├── sub-01_task-mixedgamblestask_run-03_bold.html\n","        ├── sub-01_task-mixedgamblestask_run-03_bold.json\n","        ├── sub-02_T1w.html\n","        ├── sub-02_T1w.json\n","        ├── sub-02_task-mixedgamblestask_run-01_bold.html\n","        ├── sub-02_task-mixedgamblestask_run-01_bold.json\n","        ├── sub-02_task-mixedgamblestask_run-02_bold.html\n","        ├── sub-02_task-mixedgamblestask_run-02_bold.json\n","        ├── sub-02_task-mixedgamblestask_run-03_bold.html\n","        ├── sub-02_task-mixedgamblestask_run-03_bold.json\n","        ├── sub-03_T1w.html\n","        ├── sub-03_T1w.json\n","        ├── sub-03_task-mixedgamblestask_run-01_bold.html\n","        ├── sub-03_task-mixedgamblestask_run-01_bold.json\n","        ├── sub-03_task-mixedgamblestask_run-02_bold.html\n","        ├── sub-03_task-mixedgamblestask_run-02_bold.json\n","        ├── sub-03_task-mixedgamblestask_run-03_bold.html\n","        └── sub-03_task-mixedgamblestask_run-03_bold.json\n","```\n","\n","\n","\n","    The outputs of your job is in volumes/outputs\n","\n","\n","\n","* Volumes folder contains the outputs of our job\n","* stdout contains things printed to the console like outputs, etc.\n","* stderr contains any errors. In this case, since there are no errors, it's will be empty"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0_DRSYbqKePQ","vscode":{"languageId":"python"}},"outputs":[],"source":["%%bash\n","bacalhau describe $(cat job_id.txt) --spec > job.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HWaY9_LjKiSO","vscode":{"languageId":"python"}},"outputs":[],"source":["%%bash\n","cat job.yaml"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMDr3jEBJlPnNbkWRWf/8bR","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}
