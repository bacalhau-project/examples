{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular Dynamics with Bacalhau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bacalhau-project/examples/blob/main/Gromacs/BIDS/index.ipynb)\n",
    "[![Open In Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/bacalhau-project/examples/HEAD?labpath=miscellaneous/Gromacs/index.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkl4pUzm6b2N"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "GROMACS is a package for high-performance molecular dynamics and output analysis.\n",
    "\n",
    "Molecular dynamics is a computer simulation method for analyzing the physical movements of atoms and molecules\n",
    "\n",
    "In this example we will make use of [gmx pdb2gmx](https://manual.gromacs.org/documentation/current/onlinehelp/gmx-pdb2gmx.html#description) program to add hydrogens to the molecules and generates coordinates in Gromacs (Gromos) format and a topology in Gromacs format\n",
    "\n",
    "\n",
    "\n",
    "## **Downloading datasets**\n",
    "\n",
    "Datasets can be found here [https://www.rcsb.org](https://www.rcsb.org), In this example we use \n",
    "\n",
    "[RCSB PDB - 1AKI](https://www.rcsb.org/structure/1AKI) dataset\n",
    "\n",
    "After downloading place it in a folder called “input”\n",
    "\n",
    "\n",
    "```\n",
    "input\n",
    "└── 1AKI.pdb\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### **Uploading the datasets to IPFS**\n",
    "\n",
    "Upload the directory to IPFS using IPFS CLI ([Installation Instructions](https://docs.ipfs.tech/install/command-line/#official-distributions)) [Not recommended]\n",
    "\n",
    "\n",
    "```\n",
    "$ ipfs add -r input/\n",
    "added QmTCCqPzX3qSJHuMeSma9uCqUnriZ5eJX7MnxebxydL89f input/1AKI.pdb\n",
    "added QmeeEB1YMrG6K8z43VdsdoYmQV46gAPQCHotZs9pwusCm9 input\n",
    " 113.59 KiB / 113.59 KiB [============================================================================================] 100.00%\n",
    "```\n",
    "\n",
    "\n",
    "Copy the CID in the end which is `QmeeEB1YMrG6K8z43VdsdoYmQV46gAPQCHotZs9pwusCm9 `\n",
    "\n",
    "Upload the directory to IPFS using [Pinata](https://app.pinata.cloud/) (Recommended)\n",
    "\n",
    "Click on the upload folder button and select the datasets folder that you want to upload\n",
    "![](https://i.imgur.com/TfNP9Lv.png)\n",
    "\n",
    "After the Upload has finished copy the CID (highlighted part)\n",
    "\n",
    "![](https://i.imgur.com/WO6QlN4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5EOt3Iz61vh"
   },
   "source": [
    "\n",
    "\n",
    "#### **Running the command on bacalhau**\n",
    "\n",
    "This command converts coordinate files to topology and FF-compliant coordinate files\n",
    "\n",
    "`bacalhau docker run` using the docker backend\n",
    "\n",
    "`-v QmeeEB1YMrG6K8z43VdsdoYmQV46gAPQCHotZs9pwusCm9:/input` here we mount the CID of the dataset we uploaded to IPFS and mount it to a folder called data on the container\n",
    "\n",
    "`gromacs/gromacs` We’ll use the official [gromacs - Docker Image](https://hub.docker.com/r/gromacs/gromacs) \n",
    "\n",
    "-f `input/1AKI.pdb` input file\n",
    "\n",
    "-o `output/1AKI_processed.gro` output file\n",
    "\n",
    "-water Water model to use in this case we use spc\n",
    "\n",
    "Additional parameters could be found here [gmx pdb2gmx — GROMACS 2022.2 documentation](https://manual.gromacs.org/documentation/current/onlinehelp/gmx-pdb2gmx.html) \n",
    "\n",
    " (similar tutorial you can try yourself [KALP-15 in DPPC - GROMACS Tutorial](http://www.mdtutorials.com/gmx/membrane_protein/01_pdb2gmx.html) )\n",
    "\n",
    "\n",
    "```\n",
    "bacalhau docker run \\\n",
    "-v QmeeEB1YMrG6K8z43VdsdoYmQV46gAPQCHotZs9pwusCm9:/input \\\n",
    "gromacs/gromacs \\\n",
    "-- /bin/bash -c 'echo 15 | gmx pdb2gmx -f input/1AKI.pdb -o outputs/1AKI_processed.gro -water spc'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24HuygvzTwnT"
   },
   "source": [
    "Insalling bacalhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3712,
     "status": "ok",
     "timestamp": 1663499759698,
     "user": {
      "displayName": "Vedant Padwal",
      "userId": "05534807475078682627"
     },
     "user_tz": -330
    },
    "id": "W1joNKGJT5eN",
    "outputId": "a703088d-4c44-426a-a24d-6e928159898b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your system is linux_amd64\n",
      "No BACALHAU detected. Installing fresh BACALHAU CLI...\n",
      "Getting the latest BACALHAU CLI...\n",
      "Installing v0.2.3 BACALHAU CLI...\n",
      "Downloading https://github.com/filecoin-project/bacalhau/releases/download/v0.2.3/bacalhau_v0.2.3_linux_amd64.tar.gz ...\n",
      "Downloading sig file https://github.com/filecoin-project/bacalhau/releases/download/v0.2.3/bacalhau_v0.2.3_linux_amd64.tar.gz.signature.sha256 ...\n",
      "Verified OK\n",
      "Extracting tarball ...\n",
      "NOT verifying Bin\n",
      "bacalhau installed into /usr/local/bin successfully.\n",
      "Client Version: v0.2.3\n",
      "Server Version: v0.2.3\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -sL https://get.bacalhau.org/install.sh | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Htb8W95DU8av"
   },
   "outputs": [],
   "source": [
    "%%bash --out job_id\n",
    "bacalhau docker run \\\n",
    "--id-only \\\n",
    "--wait \\ \n",
    "-v QmeeEB1YMrG6K8z43VdsdoYmQV46gAPQCHotZs9pwusCm9:/input \\\n",
    "gromacs/gromacs\n",
    "-- /bin/bash -c 'echo 15 | gmx pdb2gmx -f input/1AKI.pdb -o outputs/1AKI_processed.gro -water spc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env JOB_ID={job_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UszrZGs4c4i9"
   },
   "source": [
    "\n",
    "Running the commands will output a UUID (like `54506541-4eb9-45f4-a0b1-ea0aecd34b3e`). This is the ID of the job that was created. You can check the status of the job with the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jY8x0oyWc6Dq"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "bacalhau list --id-filter ${JOB_ID} --wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFYpNA32c7t5"
   },
   "source": [
    "\n",
    "Where it says \"`Completed `\", that means the job is done, and we can get the results.\n",
    "\n",
    "To find out more information about your job, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDnxNH3lVbG1"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "bacalhau describe ${JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2I4DHnt0Vzua"
   },
   "source": [
    "Since there is no error we can’t see any error instead we see the state of our job to be complete, that means \n",
    "we can download the results!\n",
    "we create a temporary directory to save our results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SuXkeV-WD7j"
   },
   "source": [
    "To Download the results of your job, run \n",
    "\n",
    "---\n",
    "\n",
    "the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15175,
     "status": "ok",
     "timestamp": 1663503591277,
     "user": {
      "displayName": "Vedant Padwal",
      "userId": "05534807475078682627"
     },
     "user_tz": -330
    },
    "id": "Ha5UFWLYV_5R",
    "outputId": "c8220180-3afa-4bfc-9e5f-a6ea5919c853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m12:19:36.609 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mbacalhau/get.go:67\u001b[0m\u001b[36m >\u001b[0m Fetching results of job 'ab354ccc-f02e-4262-ad0b-f33ec78803cc'...\n",
      "2022/09/18 12:19:37 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 2048 kiB, got: 416 kiB). See https://github.com/lucas-clemente/quic-go/wiki/UDP-Receive-Buffer-Size for details.\n",
      "\u001b[90m12:19:47.364 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mipfs/downloader.go:115\u001b[0m\u001b[36m >\u001b[0m Found 1 result shards, downloading to temporary folder.\n",
      "\u001b[90m12:19:51.091 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mipfs/downloader.go:195\u001b[0m\u001b[36m >\u001b[0m Combining shard from output volume 'outputs' to final location: '/content/results'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf results && mkdir -p results\n",
    "bacalhau get $JOB_ID --output-dir results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrZcHon2WOd-"
   },
   "source": [
    "After the download has finished you should \n",
    "see the following contents in results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1663503614756,
     "user": {
      "displayName": "Vedant Padwal",
      "userId": "05534807475078682627"
     },
     "user_tz": -330
    },
    "id": "C5EmAu29WRpa",
    "outputId": "a8c56ce7-e4f6-4664-a669-734b4f26f31a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shards\tstderr\tstdout\tvolumes\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "god7GNC67Rte"
   },
   "source": [
    "\n",
    "The structure of the files and directories will look like this:\n",
    "\n",
    "\n",
    "```\n",
    ".\n",
    "├── shards\n",
    "│   └── job-11940c6f-31b2-4def-952c-1b5f9eb09e4e-shard-0-host-QmYgxZiySj3MRkwLSL4X2MF5F9f2PMhAE3LV49XkfNL1o3\n",
    "│       ├── exitCode\n",
    "│       ├── stderr\n",
    "│       └── stdout\n",
    "├── stderr\n",
    "├── stdout\n",
    "└── volumes\n",
    "    └── outputs\n",
    "        └── 1AKI_processed.gro\n",
    "```\n",
    "\n",
    "\n",
    "You can see your the processed ‘`1AKI_processed`’ file in combined_results/outputs\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNx7LtoDYuzfHh2OssI7uSu",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
