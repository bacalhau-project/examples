{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3P8SDGweI-t"
      },
      "source": [
        "# Generate Realistic Images using StyleGAN3\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "With StyleGAN3 we can generate realistic looking images or videos. It can generate not only human faces, but also animals, cars and landscapes.\n",
        "\n",
        "StyleGAN is based on Generative Adversarial Networks (GANs), which includes a generator and discriminator network that has been trained to differentiate images generated by generator from real images. However, during the training the generator tries to fool the discriminator, which results in the generatation of realistic looking images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisite\n",
        "\n",
        "- To run StyleGAN3 you need to match these [requirements](https://github.com/NVlabs/stylegan3#requirements)\n",
        "\n",
        "- The Bacalhau client - [Installation instructions](https://docs.bacalhau.org/getting-started/installation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsO5M3TTeIrf"
      },
      "source": [
        "\n",
        "## Running StyleGAN3 locally\n",
        "\n",
        "To run StyleGAN3 locally, you'll need to clone the repo, install dependencies and download the model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "git clone https://github.com/NVlabs/stylegan3\n",
        "cd stylegan3\n",
        "conda env create -f environment.yml\n",
        "conda activate stylegan3\n",
        "wget https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH1JJNSeeX_1"
      },
      "source": [
        "Generate an image using pre-trained `AFHQv2` model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "python gen_images.py --outdir=out --trunc=1 --seeds=2 --network=stylegan3-r-afhqv2-512x512.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o_bBKkQeiAT"
      },
      "source": [
        "\n",
        "\n",
        "Viewing the output image\n",
        "\n",
        "![](https://i.imgur.com/A3UExJr.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMPFmPkUerVF"
      },
      "source": [
        "\n",
        "## Building the docker image\n",
        "\n",
        "Instead of building from scratch we add the following lines to the existing docker file in the repo. Copy and paste the following lines of code to the container and set some other variables.\n",
        "\n",
        "\n",
        "```\n",
        "COPY . /scratch\n",
        "\n",
        "WORKDIR /scratch\n",
        "\n",
        "ENV HOME /scratch\n",
        "```\n",
        "\n",
        "\n",
        "This step is done in the docker run command but since we’re running the command on a remote machine mounting local directory is not possible, so we add this step to the Dockerfile.\n",
        "\n",
        "To build the docker container, run the docker build command\n",
        "\n",
        "\n",
        "```\n",
        "docker build -t <hub-user>/<repo-name>:<tag> .\n",
        "```\n",
        "\n",
        "\n",
        "Replace the following:\n",
        "\n",
        "- `&lt;hub-user>`: with your docker hub username, If you don’t have a docker hub account [Follow these instructions to create docker account](https://docs.docker.com/docker-id/), and use the username of the account you created\n",
        "\n",
        "- `&lt;repo-name>`: This is the name of the container, you can name it anything you want\n",
        "\n",
        "- `&lt;tag>`: This is not required but you can use the latest tag\n",
        "\n",
        "After you have build the container, the next step is to test it locally and then push it docker hub.\n",
        "\n",
        "You'll need to push this repository to the registry designated by its name or tag.\n",
        "\n",
        "\n",
        "```\n",
        "docker push <hub-user>/<repo-name>:<tag>\n",
        "```\n",
        "\n",
        "\n",
        "After the repo image has been pushed to docker hub, we can now run the container on Bacalhau.\n",
        "\n",
        "## Running the container on Bacalhau\n",
        "\n",
        "Now we're ready to submit a Bacalhau job using your custom container. This code runs a job, downloads the results and prints the stdout. \n",
        "\n",
        "The command below is similar to what we have run locally but we changed the output directory to the outputs folder so that the results are saved to IPFS.\n",
        "\n",
        "We use the `--gpu` flag to denote the no of GPU we are going to use\n",
        "\n",
        "\n",
        "```\n",
        "bacalhau docker run \\\n",
        "jsacex/stylegan3 \\\n",
        "--gpu 1 \\\n",
        "--timeout 3600 \\\n",
        "--wait-timeout-secs 3600 \\\n",
        "-- python gen_images.py --outdir=../outputs --trunc=1 --seeds=2 --network=stylegan3-r-afhqv2-512x512.pkl\n",
        "```\n",
        "\n",
        "\n",
        "You can also run variations of this command to generate videos and other things.\n",
        "\n",
        "In the following command below, we will render a latent vector interpolation video. This will render a 4x2 grid of interpolations for seeds 0 through 31.\n",
        "\n",
        "\n",
        "```\n",
        "bacalhau docker run \\\n",
        "jsacex/stylegan3 \\\n",
        "--gpu 1 \\\n",
        "--timeout 3600 \\\n",
        "--wait-timeout-secs 3600 \\\n",
        "-- python gen_video.py --output=../outputs/lerp.mp4 --trunc=1 --seeds=0-31 --grid=4x2 --network=stylegan3-r-afhqv2-512x512.pkl\n",
        "```\n",
        "  \n",
        "Parameters for `gen_video.py` animation length and seed keyframes:\n",
        "\n",
        "    The animation length is either determined based on the --seeds value or explicitly\n",
        "\n",
        "    specified using the --num-keyframes option.\n",
        "\n",
        "    When num keyframes is specified with --num-keyframes, the output video length\n",
        "\n",
        "    will be 'num_keyframes*w_frames' frames.\n",
        "\n",
        "    If --num-keyframes is not specified, the number of seeds given with\n",
        "\n",
        "    --seeds must be divisible by grid size W*H (--grid).  In this case the\n",
        "\n",
        "    output video length will be '# seeds/(w*h)*w_frames' frames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get your Bacalhau job information\n",
        "\n",
        "Command to get your job ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4f758052-0543-40b5-bd86-6ab41e77389a\n"
          ]
        }
      ],
      "source": [
        "%%bash --out job_id\n",
        "bacalhau docker run \\\n",
        "--wait \\\n",
        "--id-only \\\n",
        "--gpu 1 \\\n",
        "--timeout 3600 \\\n",
        "--wait-timeout-secs 3600 \\\n",
        "jsacex/stylegan3 \\\n",
        "-- python gen_images.py --outdir=../outputs --trunc=1 --seeds=2 --network=stylegan3-r-afhqv2-512x512.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92;100m CREATED  \u001b[0m\u001b[92;100m ID       \u001b[0m\u001b[92;100m JOB                     \u001b[0m\u001b[92;100m STATE     \u001b[0m\u001b[92;100m VERIFIED \u001b[0m\u001b[92;100m PUBLISHED               \u001b[0m\n",
            "\u001b[97;40m 17:33:46 \u001b[0m\u001b[97;40m 4f758052 \u001b[0m\u001b[97;40m Docker jsacex/stable... \u001b[0m\u001b[97;40m Completed \u001b[0m\u001b[97;40m          \u001b[0m\u001b[97;40m /ipfs/QmcQEQPg934Pow... \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "bacalhau list --id-filter ${JOB_ID} --wide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFYpNA32c7t5"
      },
      "source": [
        "\n",
        "Where it says \"`Completed`\", that means the job is done, and we can get the results.\n",
        "\n",
        "To find out more information about your job, run the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "bacalhau describe ${JOB_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I4DHnt0Vzua"
      },
      "source": [
        "Since there is no error, we won't see any error instead we see the state of our job to be complete, that means we can download the results!\n",
        "Next is to create a temporary directory to save our results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SuXkeV-WD7j"
      },
      "source": [
        "To download the results of your job, run the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90m17:38:25.343 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mbacalhau/get.go:67\u001b[0m\u001b[36m >\u001b[0m Fetching results of job '4f758052-0543-40b5-bd86-6ab41e77389a'...\n",
            "2022/09/29 17:38:25 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 2048 kiB, got: 416 kiB). See https://github.com/lucas-clemente/quic-go/wiki/UDP-Receive-Buffer-Size for details.\n",
            "\u001b[90m17:38:35.851 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mipfs/downloader.go:115\u001b[0m\u001b[36m >\u001b[0m Found 1 result shards, downloading to temporary folder.\n",
            "\u001b[90m17:38:37.1 |\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mipfs/downloader.go:195\u001b[0m\u001b[36m >\u001b[0m Combining shard from output volume 'outputs' to final location: '/content/results'\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "rm -rf results && mkdir -p results\n",
        "bacalhau get $JOB_ID --output-dir results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrZcHon2WOd-"
      },
      "source": [
        "After the download has finished you should \n",
        "see the following contents in results directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shards\tstderr\tstdout\tvolumes\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "ls results/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
