{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: YOLO-Object-Detection\n",
    "sidebar_position: 3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lvnnY58qUfw"
   },
   "source": [
    "# YOLOv5 (Object detection) on bacalhau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bacalhau-project/examples/blob/main/model-inference/object-detection-yolo5/index.ipynb)\n",
    "[![Open In Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/bacalhau-project/examples/HEAD?labpath=model-inference/object-detection-yolo5/index.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLUmGFslqUcU"
   },
   "source": [
    "## **Introduction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYX7WHwyqUZL"
   },
   "source": [
    "\n",
    "Identification and localization of objects in photos is a computer vision task called ‘object detection, several algorithms have emerged in the past few years to tackle the problem. One of the most popular algorithms to date for real-time object detection is [YOLO (You Only Look Once)](https://towardsdatascience.com/yolo-you-only-look-once-real-time-object-detection-explained-492dc9230006), initially proposed by Redmond et. al [[1]](https://arxiv.org/abs/1506.02640).\n",
    "\n",
    "Unfortunately, many of these models require enormous amounts of training materials to get high-quality results out of the model. For many organizations looking to run object detection, they may not have access to well-labeled training data, limiting the utility of these models. However, the advent of sharing pre-trained models to do inference, without training the model, offers the best of both worlds: better results with less or no training.\n",
    "\n",
    "In this tutorial you will perform an end-to-end object detection inference,\n",
    "\n",
    "using the [YOLOv5 Docker Image developed by Ultralytics.](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIzdqZzvqUPv"
   },
   "source": [
    "\n",
    "Identification and localization of objects in photos is a computer vision task called ‘object detection, several algorithms have emerged in the past few years to tackle the problem. One of the most popular algorithms to date for real-time object detection is [YOLO (You Only Look Once)](https://towardsdatascience.com/yolo-you-only-look-once-real-time-object-detection-explained-492dc9230006), initially proposed by Redmond et. al [[1]](https://arxiv.org/abs/1506.02640).\n",
    "\n",
    "Unfortunately, many of these models require enormous amounts of training materials to get high-quality results out of the model. For many organizations looking to run object detection, they may not have access to well-labeled training data, limiting the utility of these models. However, the advent of sharing pre-trained models to do inference, without training the model, offers the best of both worlds: better results with less or no training.\n",
    "\n",
    "In this tutorial you will perform an end-to-end object detection inference,\n",
    "\n",
    "using the [YOLOv5 Docker Image developed by Ultralytics.](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qr2kbc0yqUEV"
   },
   "source": [
    "\n",
    "## **Advantages of using bacalhau**\n",
    "\n",
    "Using Bacalhau you can do the Object Detection inference on GPUs, and you don’t need to have all the images stored on your local machine they can be stored on IPFS \n",
    "\n",
    "Since the outputs are stored on IPFS you don’t need to download them on your local machine\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Zq7-UpMriiZ"
   },
   "source": [
    "Insalling bacalhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2681,
     "status": "ok",
     "timestamp": 1663505950883,
     "user": {
      "displayName": "Vedant Padwal",
      "userId": "05534807475078682627"
     },
     "user_tz": -330
    },
    "id": "0jRk48PVrgHU",
    "outputId": "3dd41285-0975-43a1-831e-967d220eb8dc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your system is linux_amd64\n",
      "No BACALHAU detected. Installing fresh BACALHAU CLI...\n",
      "Getting the latest BACALHAU CLI...\n",
      "Installing v0.2.3 BACALHAU CLI...\n",
      "Downloading https://github.com/filecoin-project/bacalhau/releases/download/v0.2.3/bacalhau_v0.2.3_linux_amd64.tar.gz ...\n",
      "Downloading sig file https://github.com/filecoin-project/bacalhau/releases/download/v0.2.3/bacalhau_v0.2.3_linux_amd64.tar.gz.signature.sha256 ...\n",
      "Verified OK\n",
      "Extracting tarball ...\n",
      "NOT verifying Bin\n",
      "bacalhau installed into /usr/local/bin successfully.\n",
      "Client Version: v0.2.3\n",
      "Server Version: v0.2.3\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -sL https://get.bacalhau.org/install.sh | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GImspWIqlc2"
   },
   "source": [
    "\n",
    "## **Running the job**\n",
    "\n",
    "To get started we run object detection on images already present inside the container\n",
    "\n",
    "If you want to use your custom images as an input please refer [Using custom Images as an input](#Uploading-Images-to-IPFS)\n",
    "\n",
    "\n",
    "Command:\n",
    "\n",
    "```\n",
    " bacalhau docker run \\\n",
    "--gpu 1   \\\n",
    "-u https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt:/usr/src/app/yolov5s.pt \\\n",
    "ultralytics/yolov5:latest \\\n",
    "-- /bin/bash -c 'python detect.py --weights yolov5s.pt --source $(pwd)/data/images --project ../../../outputs'\n",
    "```\n",
    "\n",
    "Structure of the command:\n",
    "\n",
    "\n",
    "\n",
    "* Specify the command` bacalhau docker run` which is equivalent to docker run\n",
    "* --gpu 1 specify the number of GPUs\n",
    "* `-u` you can select the weights that you want from here [yolov5 release page](https://github.com/ultralytics/yolov5/releases)\n",
    "\n",
    "the model requires weights for it to run, so it downloads the weights from github but since bacalhau doesn’t have networking enabled, you need to mount the weights and mount them to the pwd which in this case is /usr/src/app, so we specify the mount path /usr/src/app/yolov5s.pt\n",
    "\n",
    "\n",
    "You can also provide your own weights, \n",
    "\n",
    "* `ultralytics/yolov5:latest` specify the container image you want to use\n",
    "* `-- /bin/bash -c` here we specify the command we want to execute\n",
    "\n",
    "we will run the script detect.py which is for object detection\n",
    "\n",
    "\n",
    "Specify the path to the weights and source of the images \n",
    "\n",
    "\n",
    "`--project` here specify the output volume which you want to save to bacalhau   mounts an output volume called ‘outputs’ so we save the outputs there, for more flags refer [yolov5/detect.py at master](https://github.com/ultralytics/yolov5/blob/master/detect.py#L3-#L25) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1663505883701,
     "user": {
      "displayName": "Vedant Padwal",
      "userId": "05534807475078682627"
     },
     "user_tz": -330
    },
    "id": "8FDrTgcwo8g_",
    "outputId": "5f8b3e71-90ca-47ea-d175-5b69d7fab014"
   },
   "outputs": [],
   "source": [
    "%%bash --out job_id\n",
    "bacalhau docker run \\\n",
    "--gpu 1 \\\n",
    "--wait \\\n",
    "--wait-timeout-secs 1000 \\\n",
    "--id-only \\\n",
    "-u https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt \\\n",
    "ultralytics/yolov5:latest \\\n",
    "-- /bin/bash -c 'python detect.py --weights ../../../inputs/yolov5s.pt --source $(pwd)/data/images --project ../../../outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env JOB_ID={job_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nty3mMUnq9vP"
   },
   "source": [
    "\n",
    "This should output a UUID (like `59c59bfb-4ef8-45ac-9f4b-f0e9afd26e70`). This is the ID of the job that was created. You can check the status of the job with the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tl6KdTc_q8JQ"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "bacalhau list --id-filter ${JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Scc3Ro9rsWz"
   },
   "source": [
    "\n",
    "Where it says \"`Completed `\", that means the job is done, and we can get the results.\n",
    "\n",
    "To find out more information about your job, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRRiL8cDrwWu"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "bacalhau describe ${JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hItXqHymryxz"
   },
   "source": [
    "Since there is no error we can’t see any error instead we see the state of our job to be complete, that means \n",
    "we can download the results!\n",
    "we create a temporary directory to save our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATiS4xcarzu1"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geEmznFlr2m0"
   },
   "source": [
    "To Download the results of your job, run \n",
    "\n",
    "---\n",
    "\n",
    "the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxxZoLaBr4Hi"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "bacalhau get  ${JOB_ID} --output-dir results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrZcHon2WOd-"
   },
   "source": [
    "After the download has finished you should \n",
    "see the following contents in results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1663503614756,
     "user": {
      "displayName": "Vedant Padwal",
      "userId": "05534807475078682627"
     },
     "user_tz": -330
    },
    "id": "C5EmAu29WRpa",
    "outputId": "a8c56ce7-e4f6-4664-a669-734b4f26f31a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shards\tstderr\tstdout\tvolumes\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stuzxCbDsCtG"
   },
   "source": [
    "\n",
    "\n",
    "The structure of the files and directories will look like this:\n",
    "\n",
    "\n",
    "```\n",
    ".\n",
    "├── shards\n",
    "│   └── job-59c59bfb-4ef8-45ac-9f4b-f0e9afd26e70-shard-0-host-QmdZQ7ZbhnvWY1J12XYKGHApJ6aufKyLNSvf8jZBrBaAVL\n",
    "│   ├── exitCode\n",
    "│   ├── stderr\n",
    "│   └── stdout\n",
    "├── stderr\n",
    "├── stdout\n",
    "└── volumes\n",
    "└── outputs\n",
    "├── bus.jpg\n",
    "└── zidane.jpg\n",
    "```\n",
    "\n",
    "\n",
    "The Folder were our labelled images are stored is /volumes/outputs\n",
    "\n",
    "\n",
    "the outputs of your job will be downloaded in volumes/outputs/\n",
    "\n",
    "\n",
    "Viewing the results image bus.jpg\n",
    "![](https://i.imgur.com/0Zk3zNz.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62y7nvvJtw7W"
   },
   "source": [
    "\n",
    "\n",
    "# Using custom Images as an input\n",
    "\n",
    "To run Object Detection with your own images firstly you need to already have Images stored on IPFS/Filecoin or upload the Images to IPFS/FIlecoin\n",
    "\n",
    "In this command we are using the [Cyclist Dataset for Object Detection | Kaggle](https://www.kaggle.com/datasets/f445f341fc5e3ab58757efa983a38d6dc709de82abd1444c8817785ecd42a1ac) dataset \n",
    "\n",
    "The weights can be downloaded from this link [YOLOv5s](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt) or you can choose your own weights from [yolov5 release page](https://github.com/ultralytics/yolov5/releases) or even upload your own custom weights\n",
    "\n",
    "\n",
    "### **Uploading Images to IPFS**\n",
    "\n",
    "To test whether if our script works we upload 10 Images of the whole dataset along with weights\n",
    "\n",
    "The directory structure of our dataset should look like\n",
    "\n",
    "\n",
    "```\n",
    "datasets\n",
    "├── 008710.jpg\n",
    "├── 008711.jpg\n",
    "├── 008712.jpg\n",
    "├── 008713.jpg\n",
    "├── 008714.jpg\n",
    "├── 008715.jpg\n",
    "├── 008716.jpg\n",
    "├── 008717.jpg\n",
    "├── 008718.jpg\n",
    "├── 008719.jpg\n",
    "└── yolov5s.pt\n",
    "```\n",
    "\n",
    "\n",
    "Uploading datasets directory to IPFS using the ipfs cli (Not recommended)\n",
    "\n",
    "we run the following command for that\n",
    "\n",
    "\n",
    "```\n",
    "$ ipfs add -r images-10/\n",
    "added QmaoAngi85Rr3na1xSUdbC4F9Qv3CsT75KZUs7mVfdqQRX images-10/008710.jpg\n",
    "added QmbTP6J9eAXpDvxLopH6GmNmgjR7WsJHdvhdQQ4iKmZdXh images-10/008711.jpg\n",
    "added QmedfJnxJkZp2wQ5XNr7fbo4T7upr2eNTSJSrVceMU7JtY images-10/008712.jpg\n",
    "added QmYHsXG1aR46PCPtgjZ1zQuFs3Mv8sFDcgFg73LhrHUKnf images-10/008713.jpg\n",
    "added QmawStm5oDn4VPKsn9CAorAzJRfZKqsJoTe4n5TyosifAq images-10/008714.jpg\n",
    "added QmU3Qim3o7BhTsUee68EyzxrTDjJzgQUUTgBZ6SQfuSBgL images-10/008715.jpg\n",
    "added Qmbyhz2HTgiwo4dA5w4p2GcksTtxVmpcfGzcTCGz4mBBce images-10/008716.jpg\n",
    "added QmQqimRW8Ng1z2dsMsKH1KBHy637d2H88QAzBXecavwT4a images-10/008717.jpg\n",
    "added QmYsdTXKYsSriVG9a5Khv3qyt5oZog8Jdc82tvNunyybsa images-10/008718.jpg\n",
    "added QmXHpTMvxARbEufWPDxu6xfSAC2QZGqW6xx492xCsL5Vob images-10/008719.jpg\n",
    "added QmTv8e1W4q19CvX46fBxeit3SqaSB4ERcjcJUR4UnHyDoX images-10/yolov5s.pt\n",
    "added QmVkqsJySdytkY75zdQGNQHqJc4naXtMDAVTD5gwZShAmd images-10\n",
    " 15.77 MiB / 15.77 MiB [=======================================================================================] 100.00%\n",
    "```\n",
    "\n",
    "\n",
    "Since the data Uploaded To IPFS isn’t pinned or will be garbage collected\n",
    "\n",
    "The Data needs to be Pinned, Pinning is the mechanism that allows you to tell IPFS to always keep a given object somewhere, the default being your local node, though this can be different if you use a third-party remote pinning service.\n",
    "\n",
    "There a different pinning services available you can you any one of them\n",
    "\n",
    "\n",
    "## [Pinata](https://app.pinata.cloud/)\n",
    "\n",
    "Click on the upload folder button\n",
    "\n",
    "![](https://i.imgur.com/crnkrwy.png)\n",
    "\n",
    "After the Upload has finished copy the CID\n",
    "\n",
    "![](https://i.imgur.com/2Zs884R.png)\n",
    "\n",
    "\n",
    "### [NFT.Storage](https://nft.storage/) (Recommneded Option)\n",
    "\n",
    "[Upload files and directories with NFTUp](https://nft.storage/docs/how-to/nftup/) \n",
    "\n",
    "To upload your dataset using NFTup just drag and drop your directory it will upload it to IPFS\n",
    "\n",
    "![](https://i.imgur.com/g3VM2Kp.png)\n",
    "\n",
    "\n",
    "Copy the CID in this case it is bafybeicyuddgg4iliqzkx57twgshjluo2jtmlovovlx5lmgp5uoh3zrvpm\n",
    "\n",
    "You can view you uploaded dataset by clicking on the Gateway URL\n",
    "\n",
    "[https://bafybeicyuddgg4iliqzkx57twgshjluo2jtmlovovlx5lmgp5uoh3zrvpm.ipfs.nftstorage.link/](https://bafybeicyuddgg4iliqzkx57twgshjluo2jtmlovovlx5lmgp5uoh3zrvpm.ipfs.nftstorage.link/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ag21ryYlt3bH"
   },
   "source": [
    "\n",
    "### **Running the command**\n",
    "\n",
    "What the -v flag does\n",
    "\n",
    "-v flag is used to mount your IPFS CIDs to the container\n",
    "\n",
    "So if you want to mount your own CID \n",
    "\n",
    "-v &lt;THE-CID-YOU-COPIED>:/&lt;PATH-OF-DIRECTORY-IN-WHICH-YOU-WANT-TO-MOUNT-THE-DATASET>\n",
    "\n",
    "In this case it will look like where we mount the CID to /datasets folder\n",
    "\n",
    "-v bafybeicyuddgg4iliqzkx57twgshjluo2jtmlovovlx5lmgp5uoh3zrvpm:/datasets\n",
    "\n",
    "\n",
    "```\n",
    "bacalhau docker run \\\n",
    "--gpu 1 \\\n",
    "-v bafybeicyuddgg4iliqzkx57twgshjluo2jtmlovovlx5lmgp5uoh3zrvpm:/datasets \\\n",
    "ultralytics/yolov5:latest \\\n",
    "-- /bin/bash -c 'python detect.py --weights ../../../datasets/yolov5s.pt --source ../../../datasets --project  ../../../outputs'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1069,
     "status": "ok",
     "timestamp": 1663508552437,
     "user": {
      "displayName": "Vedant Padwal",
      "userId": "05534807475078682627"
     },
     "user_tz": -330
    },
    "id": "VHwUGPPCt-32",
    "outputId": "45b18a50-5904-45a1-c057-26f1613bef23",
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbdf569f-7eec-4acd-b469-bd0a1a8005da\n"
     ]
    }
   ],
   "source": [
    "%%bash --out job_id\n",
    "bacalhau docker run \\\n",
    "--gpu 1 \\\n",
    "--wait \\\n",
    "--wait-timeout-secs 1000 \\\n",
    "--id-only \\\n",
    "-v bafybeicyuddgg4iliqzkx57twgshjluo2jtmlovovlx5lmgp5uoh3zrvpm:/datasets \\\n",
    "ultralytics/yolov5:latest \\\n",
    "-- python detect.py --weights ../../../datasets/yolov5s.pt --source ../../../datasets --project  ../../../outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env JOB_ID={job_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dms4N7721ovy",
    "tags": [
     "skip-execution"
    ]
   },
   "source": [
    "\n",
    "This should output a UUID (like `1f113734-cb05-4331-b049-b9b5b102259a` ). This is the ID of the job that was created. You can check the status of the job with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVOpyN4nz1qF",
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "bacalhau list --id-filter ${JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mvz37GY514cS"
   },
   "source": [
    "\n",
    "To Download the results of your job, run the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MU989QL2Vv3"
   },
   "source": [
    "we create a temporary directory to save our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fggD6Wis2Z8f",
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir custom-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gy8xoLKQ15Oz",
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "bacalhau get ${JOB_ID} --output-dir custom-results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDssLn8R22b1"
   },
   "source": [
    "\n",
    "The structure of the files and directories will look like this:\n",
    "\n",
    "\n",
    "```\n",
    "├── shards\n",
    "│   └── job-1f113734-cb05-4331-b049-b9b5b102259a-shard-0-host-QmdZQ7ZbhnvWY1J12XYKGHApJ6aufKyLNSvf8jZBrBaAVL\n",
    "│   ├── exitCode\n",
    "│   ├── stderr\n",
    "│   └── stdout\n",
    "├── stderr\n",
    "├── stdout\n",
    "└── volumes\n",
    "└── outputs\n",
    "├── 008710.jpg\n",
    "├── 008711.jpg\n",
    "├── 008712.jpg\n",
    "├── 008713.jpg\n",
    "├── 008714.jpg\n",
    "├── 008715.jpg\n",
    "├── 008716.jpg\n",
    "├── 008717.jpg\n",
    "├── 008718.jpg\n",
    "└── 008719.jpg\n",
    "```\n",
    "\n",
    "\n",
    "The labeled images are at volumes/outputs\n",
    "\n",
    "If you don’t want to download the results but still view them using a IPFS gateway \n",
    "\n",
    "[https://cloudflare-ipfs.com/ipfs/bafybeiai3v7svitueeipqcohvelpxpcex5jtuep4wnezfqjknphuewwkoq](https://cloudflare-ipfs.com/ipfs/bafybeiai3v7svitueeipqcohvelpxpcex5jtuep4wnezfqjknphuewwkoq)\n",
    "\n",
    " Just replace the CID with the CID that you got as a result from bacalhau list\n",
    "\n",
    "Running the same job on the whole dataset (13674 Images!)CID from the previous job\n",
    "\n",
    "Upload the whole dataset which contains 13674 images along with the weight file\n",
    "\n",
    "You can choose the methods mentioned above to upload your dataset directory\n",
    "\n",
    "And copy the CID bafybeifvpl2clsdy4rc72oi4iqlyyt347ms64kmmuqwuai5j2waurnsk5e\n",
    "\n",
    "Uploaded Dataset link: [https://bafybeifvpl2clsdy4rc72oi4iqlyyt347ms64kmmuqwuai5j2waurnsk5e.ipfs.nftstorage.link/](https://bafybeifvpl2clsdy4rc72oi4iqlyyt347ms64kmmuqwuai5j2waurnsk5e.ipfs.nftstorage.link/)\n",
    "\n",
    "To run on the whole dataset we just need to replace the input CID in the -v flag with the CID of the whole dataset\n",
    "\n",
    "\n",
    "```\n",
    " bacalhau docker run \\\n",
    "--gpu 1 \\\n",
    "-v bafybeifvpl2clsdy4rc72oi4iqlyyt347ms64kmmuqwuai5j2waurnsk5e:/datasets \\\n",
    "ultralytics/yolov5:latest \\\n",
    "-- /bin/bash -c 'python detect.py --weights ../../../datasets/yolov5s.pt --source ../../../datasets  --project  ../../../outputs'\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**165000 Images (27GB)**\n",
    "\n",
    "Dataset link:\n",
    "\n",
    "https://bafybeiekic3o3tuefajvlqeiyvvbq5kkr2g27qivuawpbqva7frv42radm.ipfs.nftstorage.link/\n",
    "\n",
    "\n",
    "```\n",
    "bacalhau docker run \\\n",
    "--gpu 1 \\\n",
    "-v bafybeiekic3o3tuefajvlqeiyvvbq5kkr2g27qivuawpbqva7frv42radm:/datasets \\\n",
    "ultralytics/yolov5:latest \\\n",
    "-- /bin/bash -c 'python detect.py --weights ../../../datasets/yolov5s.pt --source ../../../datasets  --project  ../../../outputs'\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "authorship_tag": "ABX9TyOSiaNGKHLxD7G03Al1KPJ4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
